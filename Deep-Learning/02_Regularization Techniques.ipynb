{"cells":[{"cell_type":"markdown","metadata":{"id":"-Vt_LzucL9bI"},"source":["# PROBLEM STATEMENT"]},{"cell_type":"markdown","metadata":{"id":"fyZiJ2qNM_XG"},"source":["- Add a dense layer with 500 units, using ReLu activation function. The input_dim=2 specifies that the input to this layer has two features.\n","\n","- Add another dense layer with 1 unit and use sigmoid activation function.\n","\n","- Configure the model to minimize binary crossentropy as the loss function, use the SGD optimizer for weight updates and monitor metrics as during training."]},{"cell_type":"markdown","metadata":{"id":"jLrZgW6ILHIm"},"source":["# DATA PREPARATION\n"]},{"cell_type":"markdown","metadata":{"id":"vVTl0lm0KW_v"},"source":["### Loading the Dataset"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":392,"status":"ok","timestamp":1708661051078,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"gShmVaEjKJrR"},"outputs":[],"source":["from sklearn.datasets import make_moons\n","from keras.layers import Dense\n","from keras.models import Sequential"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708661052425,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"AELKJSRGKUZ-"},"outputs":[],"source":["x, y = make_moons(n_samples = 100, noise=0.2, random_state = 1)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708661053852,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"0ujZy9CxK7n0","outputId":"80f76272-4cb7-4524-cdbd-3bc0e4289a32"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1.36698238 -0.23541584]\n"," [ 1.76404402 -0.34563288]\n"," [-0.37868174  0.41004375]\n"," [ 1.15113747 -0.13597622]\n"," [ 2.31168314  0.32295125]\n"," [ 0.53866045  0.73704603]\n"," [-0.93583639  1.00686001]\n"," [ 1.32563024 -0.13540284]\n"," [ 0.75398022 -0.37261326]\n"," [ 0.42764536 -0.38163078]]\n","[1 1 0 1 1 0 0 1 1 1]\n"]}],"source":["print(x[0:10])\n","\n","print(y[0:10])"]},{"cell_type":"markdown","metadata":{"id":"TebXdlmELKDg"},"source":["### Splitting the Dataset"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708661056369,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"sR36ReKZK8AG"},"outputs":[],"source":["n_train = 30      # first 30 rows for training instances\n","\n","x_train, x_test = x[:n_train, :], x[n_train:, :]\n","y_train, y_test = y[:n_train], y[n_train:]"]},{"cell_type":"markdown","metadata":{"id":"C47zMXYiNHAC"},"source":["# SEQUENTIAL MODEL"]},{"cell_type":"markdown","metadata":{"id":"82KMX_CeOFqi"},"source":["### Model Building"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":764,"status":"ok","timestamp":1708661058591,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"kRXz14RULyGZ"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.optimizers import SGD"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708661059747,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"yeDkCKmINLVE"},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Dense(500, input_dim=2, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":603,"status":"ok","timestamp":1708661067629,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"CdTaSNMrN5RW"},"outputs":[],"source":["model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0Zfo4XdqN_oF"},"source":["### Model Training"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11218,"status":"ok","timestamp":1708661080597,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"UbhBpUXcN-k5","outputId":"a2e160f5-0946-4cad-a101-58a03b6d633d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 1s 835ms/step - loss: 0.6597 - accuracy: 0.8333 - val_loss: 0.6704 - val_accuracy: 0.6857\n","Epoch 2/100\n","1/1 [==============================] - 0s 84ms/step - loss: 0.6577 - accuracy: 0.8333 - val_loss: 0.6692 - val_accuracy: 0.6857\n","Epoch 3/100\n","1/1 [==============================] - 0s 63ms/step - loss: 0.6557 - accuracy: 0.8333 - val_loss: 0.6680 - val_accuracy: 0.6857\n","Epoch 4/100\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6536 - accuracy: 0.8333 - val_loss: 0.6668 - val_accuracy: 0.6857\n","Epoch 5/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6516 - accuracy: 0.8333 - val_loss: 0.6656 - val_accuracy: 0.6857\n","Epoch 6/100\n","1/1 [==============================] - 0s 57ms/step - loss: 0.6497 - accuracy: 0.8333 - val_loss: 0.6644 - val_accuracy: 0.6857\n","Epoch 7/100\n","1/1 [==============================] - 0s 70ms/step - loss: 0.6477 - accuracy: 0.8333 - val_loss: 0.6632 - val_accuracy: 0.6857\n","Epoch 8/100\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6457 - accuracy: 0.8333 - val_loss: 0.6621 - val_accuracy: 0.6857\n","Epoch 9/100\n","1/1 [==============================] - 0s 69ms/step - loss: 0.6438 - accuracy: 0.8333 - val_loss: 0.6609 - val_accuracy: 0.6857\n","Epoch 10/100\n","1/1 [==============================] - 0s 71ms/step - loss: 0.6419 - accuracy: 0.8333 - val_loss: 0.6598 - val_accuracy: 0.6857\n","Epoch 11/100\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6399 - accuracy: 0.8333 - val_loss: 0.6586 - val_accuracy: 0.6857\n","Epoch 12/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.6380 - accuracy: 0.8333 - val_loss: 0.6575 - val_accuracy: 0.6857\n","Epoch 13/100\n","1/1 [==============================] - 0s 59ms/step - loss: 0.6362 - accuracy: 0.8333 - val_loss: 0.6564 - val_accuracy: 0.6857\n","Epoch 14/100\n","1/1 [==============================] - 0s 70ms/step - loss: 0.6343 - accuracy: 0.8333 - val_loss: 0.6553 - val_accuracy: 0.6857\n","Epoch 15/100\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6324 - accuracy: 0.8333 - val_loss: 0.6542 - val_accuracy: 0.6857\n","Epoch 16/100\n","1/1 [==============================] - 0s 70ms/step - loss: 0.6306 - accuracy: 0.8333 - val_loss: 0.6531 - val_accuracy: 0.6857\n","Epoch 17/100\n","1/1 [==============================] - 0s 63ms/step - loss: 0.6287 - accuracy: 0.8333 - val_loss: 0.6521 - val_accuracy: 0.6857\n","Epoch 18/100\n","1/1 [==============================] - 0s 62ms/step - loss: 0.6269 - accuracy: 0.8333 - val_loss: 0.6510 - val_accuracy: 0.6857\n","Epoch 19/100\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6251 - accuracy: 0.8333 - val_loss: 0.6499 - val_accuracy: 0.6857\n","Epoch 20/100\n","1/1 [==============================] - 0s 69ms/step - loss: 0.6233 - accuracy: 0.8333 - val_loss: 0.6489 - val_accuracy: 0.6857\n","Epoch 21/100\n","1/1 [==============================] - 0s 60ms/step - loss: 0.6215 - accuracy: 0.8333 - val_loss: 0.6478 - val_accuracy: 0.6857\n","Epoch 22/100\n","1/1 [==============================] - 0s 63ms/step - loss: 0.6197 - accuracy: 0.8333 - val_loss: 0.6468 - val_accuracy: 0.6857\n","Epoch 23/100\n","1/1 [==============================] - 0s 63ms/step - loss: 0.6180 - accuracy: 0.8333 - val_loss: 0.6458 - val_accuracy: 0.6857\n","Epoch 24/100\n","1/1 [==============================] - 0s 64ms/step - loss: 0.6162 - accuracy: 0.8333 - val_loss: 0.6447 - val_accuracy: 0.6857\n","Epoch 25/100\n","1/1 [==============================] - 0s 64ms/step - loss: 0.6145 - accuracy: 0.8333 - val_loss: 0.6437 - val_accuracy: 0.6857\n","Epoch 26/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.6128 - accuracy: 0.8333 - val_loss: 0.6427 - val_accuracy: 0.6857\n","Epoch 27/100\n","1/1 [==============================] - 0s 37ms/step - loss: 0.6110 - accuracy: 0.8333 - val_loss: 0.6417 - val_accuracy: 0.6857\n","Epoch 28/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.6093 - accuracy: 0.8333 - val_loss: 0.6407 - val_accuracy: 0.6857\n","Epoch 29/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6076 - accuracy: 0.8333 - val_loss: 0.6397 - val_accuracy: 0.6857\n","Epoch 30/100\n","1/1 [==============================] - 0s 38ms/step - loss: 0.6059 - accuracy: 0.8333 - val_loss: 0.6387 - val_accuracy: 0.6857\n","Epoch 31/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6043 - accuracy: 0.8333 - val_loss: 0.6378 - val_accuracy: 0.6857\n","Epoch 32/100\n","1/1 [==============================] - 0s 36ms/step - loss: 0.6026 - accuracy: 0.8333 - val_loss: 0.6368 - val_accuracy: 0.6857\n","Epoch 33/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.6009 - accuracy: 0.8333 - val_loss: 0.6359 - val_accuracy: 0.6857\n","Epoch 34/100\n","1/1 [==============================] - 0s 37ms/step - loss: 0.5993 - accuracy: 0.8333 - val_loss: 0.6349 - val_accuracy: 0.6857\n","Epoch 35/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5977 - accuracy: 0.8333 - val_loss: 0.6340 - val_accuracy: 0.6857\n","Epoch 36/100\n","1/1 [==============================] - 0s 36ms/step - loss: 0.5960 - accuracy: 0.8333 - val_loss: 0.6330 - val_accuracy: 0.6857\n","Epoch 37/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5944 - accuracy: 0.8333 - val_loss: 0.6321 - val_accuracy: 0.6857\n","Epoch 38/100\n","1/1 [==============================] - 0s 50ms/step - loss: 0.5928 - accuracy: 0.8333 - val_loss: 0.6312 - val_accuracy: 0.6857\n","Epoch 39/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.5913 - accuracy: 0.8333 - val_loss: 0.6303 - val_accuracy: 0.6857\n","Epoch 40/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.5897 - accuracy: 0.8333 - val_loss: 0.6294 - val_accuracy: 0.6857\n","Epoch 41/100\n","1/1 [==============================] - 0s 40ms/step - loss: 0.5881 - accuracy: 0.8667 - val_loss: 0.6285 - val_accuracy: 0.6857\n","Epoch 42/100\n","1/1 [==============================] - 0s 38ms/step - loss: 0.5865 - accuracy: 0.8667 - val_loss: 0.6276 - val_accuracy: 0.6857\n","Epoch 43/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5850 - accuracy: 0.8667 - val_loss: 0.6267 - val_accuracy: 0.6857\n","Epoch 44/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5835 - accuracy: 0.8667 - val_loss: 0.6258 - val_accuracy: 0.6857\n","Epoch 45/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.5819 - accuracy: 0.8667 - val_loss: 0.6249 - val_accuracy: 0.6857\n","Epoch 46/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5804 - accuracy: 0.8667 - val_loss: 0.6241 - val_accuracy: 0.6857\n","Epoch 47/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5789 - accuracy: 0.8667 - val_loss: 0.6232 - val_accuracy: 0.6857\n","Epoch 48/100\n","1/1 [==============================] - 0s 52ms/step - loss: 0.5774 - accuracy: 0.8667 - val_loss: 0.6223 - val_accuracy: 0.6857\n","Epoch 49/100\n","1/1 [==============================] - 0s 38ms/step - loss: 0.5759 - accuracy: 0.8667 - val_loss: 0.6215 - val_accuracy: 0.6857\n","Epoch 50/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.5744 - accuracy: 0.8667 - val_loss: 0.6206 - val_accuracy: 0.6857\n","Epoch 51/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5729 - accuracy: 0.8667 - val_loss: 0.6198 - val_accuracy: 0.6857\n","Epoch 52/100\n","1/1 [==============================] - 0s 56ms/step - loss: 0.5714 - accuracy: 0.8667 - val_loss: 0.6190 - val_accuracy: 0.6857\n","Epoch 53/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5700 - accuracy: 0.8667 - val_loss: 0.6181 - val_accuracy: 0.6857\n","Epoch 54/100\n","1/1 [==============================] - 0s 61ms/step - loss: 0.5685 - accuracy: 0.8667 - val_loss: 0.6173 - val_accuracy: 0.6857\n","Epoch 55/100\n","1/1 [==============================] - 0s 57ms/step - loss: 0.5671 - accuracy: 0.8667 - val_loss: 0.6165 - val_accuracy: 0.6857\n","Epoch 56/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5657 - accuracy: 0.8667 - val_loss: 0.6157 - val_accuracy: 0.6857\n","Epoch 57/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.5642 - accuracy: 0.8667 - val_loss: 0.6149 - val_accuracy: 0.6857\n","Epoch 58/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.5628 - accuracy: 0.8667 - val_loss: 0.6141 - val_accuracy: 0.6857\n","Epoch 59/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5614 - accuracy: 0.8667 - val_loss: 0.6133 - val_accuracy: 0.6857\n","Epoch 60/100\n","1/1 [==============================] - 0s 51ms/step - loss: 0.5600 - accuracy: 0.8667 - val_loss: 0.6125 - val_accuracy: 0.6857\n","Epoch 61/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5586 - accuracy: 0.8667 - val_loss: 0.6117 - val_accuracy: 0.6857\n","Epoch 62/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5572 - accuracy: 0.8667 - val_loss: 0.6109 - val_accuracy: 0.6857\n","Epoch 63/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.5558 - accuracy: 0.8667 - val_loss: 0.6101 - val_accuracy: 0.6857\n","Epoch 64/100\n","1/1 [==============================] - 0s 52ms/step - loss: 0.5544 - accuracy: 0.8667 - val_loss: 0.6094 - val_accuracy: 0.7000\n","Epoch 65/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5531 - accuracy: 0.8667 - val_loss: 0.6086 - val_accuracy: 0.7000\n","Epoch 66/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5517 - accuracy: 0.8667 - val_loss: 0.6078 - val_accuracy: 0.7000\n","Epoch 67/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5503 - accuracy: 0.8667 - val_loss: 0.6071 - val_accuracy: 0.7000\n","Epoch 68/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5490 - accuracy: 0.8667 - val_loss: 0.6063 - val_accuracy: 0.7000\n","Epoch 69/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5477 - accuracy: 0.8667 - val_loss: 0.6056 - val_accuracy: 0.7000\n","Epoch 70/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.5463 - accuracy: 0.8667 - val_loss: 0.6048 - val_accuracy: 0.7000\n","Epoch 71/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.5450 - accuracy: 0.8667 - val_loss: 0.6041 - val_accuracy: 0.7000\n","Epoch 72/100\n","1/1 [==============================] - 0s 66ms/step - loss: 0.5437 - accuracy: 0.8667 - val_loss: 0.6034 - val_accuracy: 0.7143\n","Epoch 73/100\n","1/1 [==============================] - 0s 48ms/step - loss: 0.5424 - accuracy: 0.8667 - val_loss: 0.6026 - val_accuracy: 0.7143\n","Epoch 74/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5411 - accuracy: 0.8667 - val_loss: 0.6019 - val_accuracy: 0.7143\n","Epoch 75/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5398 - accuracy: 0.8667 - val_loss: 0.6012 - val_accuracy: 0.7143\n","Epoch 76/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.5385 - accuracy: 0.8667 - val_loss: 0.6005 - val_accuracy: 0.7143\n","Epoch 77/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5372 - accuracy: 0.8667 - val_loss: 0.5998 - val_accuracy: 0.7143\n","Epoch 78/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5359 - accuracy: 0.8667 - val_loss: 0.5991 - val_accuracy: 0.7143\n","Epoch 79/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5346 - accuracy: 0.8667 - val_loss: 0.5983 - val_accuracy: 0.7143\n","Epoch 80/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5333 - accuracy: 0.8667 - val_loss: 0.5976 - val_accuracy: 0.7143\n","Epoch 81/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5321 - accuracy: 0.8667 - val_loss: 0.5970 - val_accuracy: 0.7143\n","Epoch 82/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5308 - accuracy: 0.8667 - val_loss: 0.5963 - val_accuracy: 0.7143\n","Epoch 83/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5296 - accuracy: 0.8667 - val_loss: 0.5956 - val_accuracy: 0.7143\n","Epoch 84/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5283 - accuracy: 0.8667 - val_loss: 0.5949 - val_accuracy: 0.7143\n","Epoch 85/100\n","1/1 [==============================] - 0s 41ms/step - loss: 0.5271 - accuracy: 0.8667 - val_loss: 0.5942 - val_accuracy: 0.7143\n","Epoch 86/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5259 - accuracy: 0.8667 - val_loss: 0.5935 - val_accuracy: 0.7143\n","Epoch 87/100\n","1/1 [==============================] - 0s 58ms/step - loss: 0.5247 - accuracy: 0.8667 - val_loss: 0.5929 - val_accuracy: 0.7143\n","Epoch 88/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.5234 - accuracy: 0.8667 - val_loss: 0.5922 - val_accuracy: 0.7143\n","Epoch 89/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5222 - accuracy: 0.8667 - val_loss: 0.5915 - val_accuracy: 0.7143\n","Epoch 90/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.5210 - accuracy: 0.8667 - val_loss: 0.5909 - val_accuracy: 0.7143\n","Epoch 91/100\n","1/1 [==============================] - 0s 54ms/step - loss: 0.5198 - accuracy: 0.8667 - val_loss: 0.5902 - val_accuracy: 0.7143\n","Epoch 92/100\n","1/1 [==============================] - 0s 52ms/step - loss: 0.5187 - accuracy: 0.8667 - val_loss: 0.5896 - val_accuracy: 0.7143\n","Epoch 93/100\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5175 - accuracy: 0.8667 - val_loss: 0.5889 - val_accuracy: 0.7143\n","Epoch 94/100\n","1/1 [==============================] - 0s 44ms/step - loss: 0.5163 - accuracy: 0.8667 - val_loss: 0.5883 - val_accuracy: 0.7143\n","Epoch 95/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5151 - accuracy: 0.8667 - val_loss: 0.5877 - val_accuracy: 0.7143\n","Epoch 96/100\n","1/1 [==============================] - 0s 45ms/step - loss: 0.5140 - accuracy: 0.8667 - val_loss: 0.5870 - val_accuracy: 0.7143\n","Epoch 97/100\n","1/1 [==============================] - 0s 43ms/step - loss: 0.5128 - accuracy: 0.8667 - val_loss: 0.5864 - val_accuracy: 0.7143\n","Epoch 98/100\n","1/1 [==============================] - 0s 61ms/step - loss: 0.5117 - accuracy: 0.8667 - val_loss: 0.5858 - val_accuracy: 0.7143\n","Epoch 99/100\n","1/1 [==============================] - 0s 55ms/step - loss: 0.5105 - accuracy: 0.8667 - val_loss: 0.5852 - val_accuracy: 0.7143\n","Epoch 100/100\n","1/1 [==============================] - 0s 46ms/step - loss: 0.5094 - accuracy: 0.8667 - val_loss: 0.5845 - val_accuracy: 0.7143\n","3/3 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.7143\n","\n","\n","Test loss: 0.5845329761505127, Test accuracy: 0.7142857313156128\n"]}],"source":["history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","\n","print(f\"\\n\\nTest loss: {loss}, Test accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708661080597,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"9iCKrbN-Qha2","outputId":"3c21aab4-0bf4-48ad-fe34-49d60ab5163c"},"outputs":[{"name":"stdout","output_type":"stream","text":["3/3 [==============================] - 0s 4ms/step\n"]}],"source":["y_pred = model.predict(x_test)"]},{"cell_type":"markdown","metadata":{"id":"jvHpwX2uQPEm"},"source":["### Model Performance and Overfitting"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1568,"status":"ok","timestamp":1708661088269,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"bDscpx0cOOx3","outputId":"3590e9b1-1a2a-4072-c158-59d5b2977aa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["ACCURACY :  0.5142857142857142\n","RECALL :  0.0\n","PRECISION :  0.0\n","F1 :  0.0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"data":{"text/plain":["array([[36,  0],\n","       [34,  0]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,  f1_score, precision_score\n","\n","print(\"ACCURACY : \", accuracy_score(y_test.astype(\"int32\"), y_pred.astype(\"int32\")))\n","\n","print(\"RECALL : \", recall_score(y_test.astype(\"int32\"), y_pred.astype(\"int32\")))\n","\n","print(\"PRECISION : \", precision_score(y_test.astype(\"int32\"), y_pred.astype(\"int32\")))\n","\n","print(\"F1 : \", f1_score(y_test.astype(\"int32\"), y_pred.astype(\"int32\")))\n","\n","confusion_matrix(y_test.astype(\"int32\"), y_pred.astype(\"int32\"))"]},{"cell_type":"markdown","metadata":{"id":"RFqeDp8MQwSA"},"source":["**NOTE:**\n","\n","- We can clearly see that the accuray of Training Data (84%) is clearly more than accuracy of Testing Data (48%)\n","\n","- Hence, clearly there is an issue of **OVERFIITING**."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":1788,"status":"ok","timestamp":1708661090030,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"KyDyMCw3Qm4m","outputId":"988852a3-ce48-4096-b4c4-f9b6cd156fb2"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABj6ElEQVR4nO3dd1hW9f/H8efNuBkKOBkiinuhqKiImjYoLSvbZpZmZcsc2dL6Vr+W1teGZpZlw7amaVqZI1LL3LgXOHECogKisu77/P44hvFNDRQ8N/B6XNe5rvycwfs+FffLcz7DZhiGgYiIiIgLc7O6ABEREZF/o8AiIiIiLk+BRURERFyeAouIiIi4PAUWERERcXkKLCIiIuLyFFhERETE5SmwiIiIiMvzsLqAkuJ0Ojl48CB+fn7YbDaryxEREZEiMAyD48ePU6tWLdzczv0cpdwEloMHDxIWFmZ1GSIiInIB9u3bR+3atc+5v9wEFj8/P8D8wP7+/hZXIyIiIkWRmZlJWFhYwff4uZSbwPLXayB/f38FFhERkTLm37pzqNOtiIiIuDwFFhEREXF5CiwiIiLi8spNHxYREZHSYBgG+fn5OBwOq0spk9zd3fHw8LjoKUcUWERERM4hNzeXQ4cOcfLkSatLKdN8fX0JCQnBbrdf8DUUWERERM7C6XSye/du3N3dqVWrFna7XROTFpNhGOTm5nL48GF2795No0aNzjs53PkosIiIiJxFbm4uTqeTsLAwfH19rS6nzPLx8cHT05OkpCRyc3Px9va+oOuo062IiMh5XOgTATmjJO6h/i2IiIiIy1NgEREREZenwCIiIiLnFB4eztixY60uQ51uRUREypvLL7+c1q1bl0jQWLVqFZUqVbr4oi6SAsu/+f1NyDsJXR4Hr/OvJCkiIlIWGIaBw+HAw+PfY0DNmjUvQUX/Tq+Ezicr1Qwsf7wF77aB1Z+BI9/qqkRExCKGYXAyN/+Sb4ZhFLnGe++9l8WLFzNu3DhsNhs2m43Jkydjs9n45ZdfiIqKwsvLiyVLlrBz50569epFUFAQlStXpn379vz666+Frve/r4RsNhsff/wxN998M76+vjRq1IjZs2eX1C0+Jz1hOZ9KNeHWj2HBC3B0J/w0DFZ8CN1fhYaxVlcnIiKX2Kk8B81fmHfJf+6Wl7vjay/aV/a4ceNITEwkIiKCl19+GYDNmzcDMGLECN58803q169P1apV2bdvH9dddx2vvfYaXl5efPHFF9xwww0kJCRQp06dc/6Ml156if/+97+MGTOG8ePH07dvX5KSkqhWrdrFf9hz0BOW87HZoNn18Ohy6PE6+FSFw1vhq1vhy1sgeZPVFYqIiBQSEBCA3W7H19eX4OBggoODcXd3B+Dll1/m6quvpkGDBlSrVo3IyEgeeughIiIiaNSoEa+88goNGjT41ycm9957L3369KFhw4aMGjWKrKwsVq5cWaqfS09YisLDDh0fgcg7zVdEKz6EnXGw8zdo0xeu+A/4h1hdpYiIlDIfT3e2vNzdkp9bEtq1a1foz1lZWfzf//0fP//8M4cOHSI/P59Tp06xd+/e816nVatWBf9cqVIl/P39SU1NLZEaz0WBpTh8qkL316D9/RD3MmyeCWu/gk0zIOYx6DxEHXNFRMoxm81W5Fczruh/R/s8+eSTLFiwgDfffJOGDRvi4+PDbbfdRm5u7nmv4+npWejPNpsNp9NZ4vX+nV4JXYhq9eH2yXD/AgiLNkcR/f5feLctrPpEHXNFRMRSdrsdh8Pxr8f9+eef3Hvvvdx88820bNmS4OBg9uzZU/oFXgAFlosR1gHumwd3fGGGmBOp8PNw+CAGts2BYvTqFhERKSnh4eGsWLGCPXv2kJaWds6nH40aNWLGjBmsW7eO9evXc9ddd5X6k5ILpcBysWw2aN4LHl0B1/4XfKpBWiJM6QOfXQf7V1tdoYiIVDBPPvkk7u7uNG/enJo1a56zT8rbb79N1apV6dSpEzfccAPdu3enbdu2l7jaorEZxRnc7cIyMzMJCAggIyMDf39/6wrJzoAl78DyDyA/22xrfhNc9QJUb2BdXSIiUizZ2dns3r2bevXq4e3tbXU5Zdr57mVRv7/1hKWkeQdA7P/B4Hho3RewwZYfYEIHmPMUZB22uEAREZGyR4GltATUhpveh4eXQMOrwZkPKz+Cd1vD4v9CTpbVFYqIiJQZCiylLTgC7p4O/WZDrTaQmwULXzOn+l/1CTjyrK5QRETE5SmwXCr1u8EDv8Ftn0LV8DMjiiZEm/O5lI+uRCIiIqVCgeVScnODiFth0Cq4dgz41jDXKJp2L0y6AnYttrpCERERl6TAYgUPO0Q/CEPXQbcRYK8MB9fCFzfClzfDwXVWVygiIuJSFFis5OUHV4yEIeugw0Pg5mmuT/RRN5g2AI7stLpCERERl6DA4goq14Tr/guPrYKWdwA22DwD3msPPw6DzENWVygiImIpBRZXUq0e3DoJHv4DGnUHwwHxn5kjiha8ACePWl2hiIiIJS4osEyYMIHw8HC8vb2Jjo5m5cqV5z0+PT2dQYMGERISgpeXF40bN2bOnDmFjjlw4AB333031atXx8fHh5YtW7J6dQWd1j64JfT9Dgb8Yi6umH8K/hwH4yJh8RjN4SIiIud1+eWXM2zYsBK73r333stNN91UYte7EMUOLFOnTmX48OG8+OKLrFmzhsjISLp3705qaupZj8/NzeXqq69mz549TJ8+nYSEBCZNmkRoaGjBMceOHaNz5854enryyy+/sGXLFt566y2qVq164Z+sPKjbyVxc8a7vICgCcjJh4avm5HPLJ0J+jtUVioiIXBpGMXXo0MEYNGhQwZ8dDodRq1YtY/To0Wc9/oMPPjDq169v5ObmnvOazzzzjNGlS5fillJIRkaGARgZGRkXdR2X5XAYxoZphjE20jBe9De3t1sYRvznhpGfZ3V1IiLlzqlTp4wtW7YYp06dsrqUYunfv78BFNp2795tbNy40ejRo4dRqVIlIzAw0Lj77ruNw4cPF5w3bdo0IyIiwvD29jaqVatmXHXVVUZWVpbx4osv/uN6CxcuLFZN57uXRf3+LtYTltzcXOLj44mNjS1oc3NzIzY2lmXLlp31nNmzZxMTE8OgQYMICgoiIiKCUaNG4XA4Ch3Trl07br/9dgIDA2nTpg2TJk06by05OTlkZmYW2krD+n3pfLd6X6lcu1jc3KDlbWbH3OvHgl8tyNgHswfD+9GwcTq46JLgIiLlhmFA7olLvxVjctFx48YRExPDwIEDOXToEIcOHcLPz48rr7ySNm3asHr1aubOnUtKSgp33HEHAIcOHaJPnz7cd999bN26lUWLFnHLLbdgGAZPPvkkd9xxBz169Ci4XqdOnUrrDp+TR3EOTktLw+FwEBQUVKg9KCiIbdu2nfWcXbt28dtvv9G3b1/mzJnDjh07ePTRR8nLy+PFF18sOOaDDz5g+PDhPPvss6xatYohQ4Zgt9vp37//Wa87evRoXnrppeKUX2yHMk7R/7OVpJ/MI/NUHg9cVr9Uf16RuHtCuwEQeac5tf8fb8GRHfD9/eYq0Vc8B02uBZvN6kpFRMqfvJMwqtal/7nPHgR7pSIdGhAQgN1ux9fXl+DgYABeffVV2rRpw6hRowqO+/TTTwkLCyMxMZGsrCzy8/O55ZZbqFu3LgAtW7YsONbHx4ecnJyC61mh1EcJOZ1OAgMD+eijj4iKiqJ3794899xzTJw4sdAxbdu2ZdSoUbRp04YHH3yQgQMHFjrmf40cOZKMjIyCbd++kn8KEuzvTe/2YQC8+vNW3p6fgOEqU+h7+kCnx2DYBrj8WfDyh5RNMKUPfHyVOZ+Lq9QqIiKWWr9+PQsXLqRy5coFW9OmTQHYuXMnkZGRXHXVVbRs2ZLbb7+dSZMmcezYMYurLqxYT1hq1KiBu7s7KSkphdpTUlLOmbpCQkLw9PTE3d29oK1Zs2YkJyeTm5uL3W4nJCSE5s2bFzqvWbNmfP/99+esxcvLCy8vr+KUX2w2m42R1zbD39uTMfMSePe3HWRm5/PC9c1xc3ORJxhefnD5M9BhICx9F1Z8CAfizRlz63aGK/9jdt4VEZGL5+lrPu2w4udehKysLG644QbeeOONf+wLCQnB3d2dBQsWsHTpUubPn8/48eN57rnnWLFiBfXq1buon11SivWExW63ExUVRVxcXEGb0+kkLi6OmJiYs57TuXNnduzYgfNv/SsSExMJCQnBbrcXHJOQkFDovMTExILHUlYbdEVDXu7VAoDJS/fw1PQN5DtcrL+IbzWI/T8Yuh6iHwF3OyT9CZ9da4aX/fFWVygiUvbZbOarmUu9FfM1v91uL9RXtG3btmzevJnw8HAaNmxYaKtUqdLpj2ajc+fOvPTSS6xduxa73c7MmTPPej0rFPuV0PDhw5k0aRKff/45W7du5ZFHHuHEiRMMGDAAgH79+jFy5MiC4x955BGOHj3K0KFDSUxM5Oeff2bUqFEMGjSo4JjHH3+c5cuXM2rUKHbs2ME333zDRx99VOgYq/WLCeftOyJxd7Px/Zr9DPpmDTn51v7LO6vKgXDt6+Z0/+3uAzcP8/XQx1fCN73h0HqrKxQRkVIWHh7OihUr2LNnD2lpaQwaNIijR4/Sp08fVq1axc6dO5k3bx4DBgzA4XCwYsUKRo0axerVq9m7dy8zZszg8OHDNGvWrOB6GzZsICEhgbS0NPLy8i79hyrWuKTTxo8fb9SpU8ew2+1Ghw4djOXLlxfs69atm9G/f/9Cxy9dutSIjo42vLy8jPr16xuvvfaakZ+fX+iYH3/80YiIiDC8vLyMpk2bGh999FGxarpUw5rnbjpkNHp2jlH3mZ+MuyYtM7KyXXxI8dHdhjHzUcP4vypnhkNP6WsYyZusrkxExKWV1WHNhmEYCQkJRseOHQ0fH5+CYc2JiYnGzTffbFSpUsXw8fExmjZtagwbNsxwOp3Gli1bjO7duxs1a9Y0vLy8jMaNGxvjx48vuF5qaqpx9dVXG5UrV7ZsWLPNMMpHz8zMzEwCAgLIyMjA39+/VH/WnzvSGPjFak7mOmgdVoXJA9pTxddeqj/zoqXtgMVvwMZpmMPobdDiZrh8BNRsYnV1IiIuJzs7m927d1OvXj28vb2tLqdMO9+9LOr3t9YSugCdG9bg6weiCfDxZN2+dO74cBkpmdlWl3V+NRqa6xQ9uhya3wQY5gKLE6Lh+4FmoBEREXFRCiwXqE2dqkx7OIYgfy8SU7K4beJSko6csLqsfxfYFO74HB5eAk16AgZs/A4mtIeZD8ORnVZXKCIi8g8KLBehcZAf0x/uRN3qvuw7eorbJi5j66HSmXG3xAW3hD7fwIOLofG1YDhh/bfwXnv44VE4usvqCkVERAoosFyksGq+THs4hqbBfhw+nsMdHy5j9Z6jVpdVdLVaw11TYOBv0PBqMByw7msY3w5+GKTgIiIiLkGBpQQE+nkz9aEY2tWtyvHsfO7+ZAULE86+erXLCo2Cu6fDA3F/Cy5fKbiIiIhLUGApIQE+nnx5fzRXNKlJdp6TgZ+vZta6A1aXVXy125nB5f5foWFs4eAy8xH1cRGRCqecDKa1VEncQwWWEuRjd+ejfu3o1boW+U6DYVPX8fnSPVaXdWHC2sPd358OLqefuKz/Bt5rBzMe0qgiESn3PD09ATh58qTFlZR9f93Dv+7phdA8LKXA6TR4+actTD4dVoZc1YjHYxthK8srKO+Ph8Wvw/b55p9tbhBxG3R9UvO4iEi5dejQIdLT0wkMDMTX17ds/x63gGEYnDx5ktTUVKpUqUJISMg/jinq97cCSykxDIPxv+3g7QWJAPSNrsPLvSJwd5VFEy/UgXhYPAYSfzndYIOIW6DrUxDYzNLSRERKmmEYJCcnk56ebnUpZVqVKlUIDg4+a+BTYHERXy5P4oVZmzAM6NkyhLd7R+Ll4f7vJ7q6g+vg9zGw7afTDTZofqMZXIJbWlmZiEiJczgc1qyfUw54enri7n7u7z0FFhfy84ZDDJu6ljyHQeeG1fnwnnZU9vKwuqySkbwRFv8Xts4+09akJ3R7Cmq1sa4uEREpExRYXMyS7Wk89OVqTuQ6aBkawGcD2lOjspfVZZWclC3wx5uwaQbmWkWYnXW7PQ1hHSwtTUREXJcCiwvasD+dAZ+t4siJXMKr+/Ll/dGEVfO1uqySdTgR/njLnO7fcJpt9bpC16chvAuow5qIiPyNAouL2nU4i3s+WcmB9FPU9PPii/s60CzEdeu9YEd2wpJ3zOn+nflmW1hHs49Lw6sUXEREBFBgsbqc80rJzKbfJytJSDmOn7cHk/q1o2P96laXVTrS98Kf42DNF+DINdtCWpvDoZv0BDdNBSQiUpEpsLi4jJN5PPDFKlbtOYbdw41372xNj4h/jk8vNzIPwbL3YPWnkHd6EqaazeCy4dDiFnAvJ52QRUSkWBRYyoDsPAeDv13Lgi0puNng5V4R3N2xrtVlla4TabD8A1j5EeScXtm6aj3oMgwi+4BHOeqILCIi/0qBpYzIdzh5ftZmvl25F4ChVzViWFmfFbcoTqXDqkmw7H04dXp1a79a0GkwRPUHeyVLyxMRkUtDgaUMMQyDd37dzrtx2wHo06EOr/RqgYd7BejfkXsC4j+Hpe/C8UNmm0816PgodHgAfKpaW5+IiJQqBZYy6O+z4l7dPIjxfdrg7VkOZsUtivwcWPeN2UH32G6zze4H7e+DjoPAL8ja+kREpFQosJRRczcdYsiUdeTmO4mqW5VP+rejiq/d6rIuHUc+bPkB/ngbUjebbe5e0KYvdBoC1epZWp6IiJQsBZYybOXuozzw+Soys/NpGFiZz+/rQGgVH6vLurQMAxLnmZPQ7V9pttncIOJW6DwMgiMsLU9EREqGAksZl5hynP6fruRQRjbB/t5Mvq89TYPL/ucqNsOApD/NJy474860N+oOXR6HujHW1SYiIhdNgaUcOJh+ins/W0liShZ+Xh581K8dMQ3K6QRzRXFwnTl77pZZFKxXFNbRnMul0TWaPVdEpAxSYCknMk7mMfCL1azccxS7uxtv3RHJDZG1rC7LWkd2mp1z1397ZvbcwObQeaj5ysjd09r6RESkyBRYypHsPAfDv1vHnI3JAPynZzMeuKy+xVW5gMxDsPx9c/bc3CyzLSAMYh6DtvdoLhcRkTJAgaWccTgNXvlpC5OX7gHg/i71eO66Zri56TUIp9Jh9SfmDLonDpttPtWgw0Do8CBUqmFpeSIicm4KLOWQYRh8+PsuXv9lGwA9W4Xw1u2RFWeuln+Td8qcy2Xp+DNzuXj4QJu7IWaQhkSLiLggBZZy7Ie1B3hq+nryHAYdwqvxUb+oijVXy79xOsyOuX+Og0PrzDabGzS/CToPgVptrKxORET+RoGlnFu6I42HvozneI45V8vkAe2pXdXX6rJci2HA7t/N4PL3IdH1upoddBtcpZFFIiIWU2CpALYlZ3Lvp6tIzswm0M+LT+9tT0RogNVluabkjfDnu7DpezAcZltQhLnYokYWiYhYpqjf3xe0ut6ECRMIDw/H29ub6OhoVq5ced7j09PTGTRoECEhIXh5edG4cWPmzJlz1mNff/11bDYbw4YNu5DSKpSmwf7MHNSJJkF+pB7PofeHy1iceNjqslxTcEu4dRIMXW+uTeRZCVI2wcyHYFykGWayM62uUkREzqHYgWXq1KkMHz6cF198kTVr1hAZGUn37t1JTU096/G5ublcffXV7Nmzh+nTp5OQkMCkSZMIDQ39x7GrVq3iww8/pFWrVsX/JBVUSIAP0x6JoXPD6pzIdXDf5FVMXbXX6rJcV5Uw6DEKhm+Gq16AykGQeQAWPA/vtID5/4GM/VZXKSIi/6PYr4Sio6Np37497733HgBOp5OwsDAGDx7MiBEj/nH8xIkTGTNmDNu2bcPT89yP3bOysmjbti3vv/8+r776Kq1bt2bs2LFFrqsivhL6u9x8JyNmbGDGmgMADLmyIY9f3Rib+micX34ObPjOHFmUlmC2uXlAi1ug02MQEmltfSIi5VypvBLKzc0lPj6e2NjYMxdwcyM2NpZly5ad9ZzZs2cTExPDoEGDCAoKIiIiglGjRuFwOAodN2jQIHr27Fno2ueTk5NDZmZmoa0is3u48dbtkQy5siEA7/62gyemrSc332lxZS7Ow8ucZO7R5dBnKoRfBs582PgdfNgVPr8BEueDU/dRRMRKxQosaWlpOBwOgoKCCrUHBQWRnJx81nN27drF9OnTcTgczJkzh+eff5633nqLV199teCYKVOmsGbNGkaPHl3kWkaPHk1AQEDBFhYWVpyPUi7ZbDaGX9OE129pibubjRlrDnDvZyvJOJVndWmuz80NmvSAe3+CBxdBxG1gczdHGX1zO7zfEeI/h7xsqysVEamQLqjTbXE4nU4CAwP56KOPiIqKonfv3jz33HNMnDgRgH379jF06FC+/vprvL29i3zdkSNHkpGRUbDt27evtD5CmXNnhzp80r8dlezuLN15hNsnLmX/sZNWl1V21GoDt30CQ9eZ0/zb/czXRT8OMfu5LHodstS5WUTkUipWYKlRowbu7u6kpKQUak9JSSE4OPis54SEhNC4cWPc3c/MxtqsWTOSk5MLXjGlpqbStm1bPDw88PDwYPHixbz77rt4eHj849XRX7y8vPD39y+0yRmXNwnku4djCPL3IjEli5vfX8qmAxlWl1W2VKkD3V8zO+he85q5TtHJNFg02gwuswdD6jarqxQRqRCKFVjsdjtRUVHExZ2ZhMvpdBIXF0dMTMxZz+ncuTM7duzA+bc+AImJiYSEhGC327nqqqvYuHEj69atK9jatWtH3759WbduXaGgI8XTolYAMx/tTNNgPw4fz+GOD5cRtzXl30+UwrwDzA64Q9bBrZ9ArbbgyIE1X8D70fDVrbDzN3OiOhERKRXFfiU0fPhwJk2axOeff87WrVt55JFHOHHiBAMGDACgX79+jBw5suD4Rx55hKNHjzJ06FASExP5+eefGTVqFIMGDQLAz8+PiIiIQlulSpWoXr06ERERJfQxK65aVXyY9nAMlzWqwclcBwO/WM0Xy/ZYXVbZ5O4BLW+Dgb/BffOg2Q2ADXb8Cl/eDB90MkOM+rmIiJQ4j+Ke0Lt3bw4fPswLL7xAcnIyrVu3Zu7cuQUdcffu3Yub25kcFBYWxrx583j88cdp1aoVoaGhDB06lGeeeabkPoWcl5+3J5/e257nf9jElFX7eGHWZpKOnOTZ65rhrtWei89mgzodze3oLljxIaz9ClK3mK+Jfn0J2t0H7R8Av6B/v56IiPwrTc1fgRiGwfuLdjJmnjnfyDXNgxh3Zxt87HrtdtFOpcPaL83wknG6A7ibp/lEpuMjms9FROQctJaQnNOP6w8WzNESWTuASf3bEehX9BFach6OfNj2Iyz/APatONNetzNEPwxNe4KbAqKIyF8UWOS8Vu85ysAvVnPsZB6hVXz49N72NAn2s7qs8mV/PKz4ADbPNCejAwioAx0GQtt+4FPF0vJERFyBAov8qz1pJxgweRW7007g5+XB+3e35bJGNa0uq/zJPAgrJ0H8ZDh11Gzz9IXIPuZTl5qNLS1PRMRKCixSJMdO5PLQV/Gs3H0Udzcbr94UQZ8Odawuq3zKO2WuW7RiotlB9y8NrjKDS8NYc8ZdEZEKRIFFiiwn38GI7zcyc625cOJDXevzTI+muGkEUekwDHPK/xUTIeEX4PT/gtXqQ4eHoPVd4K3/hkWkYlBgkWIxDINxcdsZ++t2ALq3COKd3q3xtRd75LsUx9HdsOpjWPMl5Jyeidhe2QwtHR6EGo2srU9EpJQpsMgF+WHtAZ6evoFch5OWoQF83L8dQf4aQVTqcrJg/bew8iNISzzT3uAqiH4IGl6t10UiUi4psMgFW73nKA9+Gc/RE7mEBHjzSf/2NK+le3pJGAbsWggrPoLEuRS8Lqpazxxd1LqvRheJSLmiwCIXJenICe6bvIqdh09Qye7Ou33acFUzzdp6SR3dBSs/NmfR/et1kWcliOxtvi4KbGZtfSIiJUCBRS5axsk8Hv0mnj93HMFmg+eua8b9Xephs6kz7iWVkwUbvzOfuhzeeqY9/DIzuDS5zlznSESkDFJgkRKR53DywqzNfLtyLwB9OtTh5V4t8HRXf4pLzjBgzx9mP5dtP4NxegV0/1BoNwDa9ofKgdbWKCJSTAosUmIMw+CTJbt5bc5WDAM6N6zO+3dFEeDraXVpFVf6Poj/DOI/h5NpZpubJ7S4CdoPhLAO5iKNIiIuToFFStyvW1IYMmUtJ3Md1K9ZiU/6t6dejUpWl1Wx5eeYU/+vnAQHVp9pD25lrhbd8naw+1pXn4jIv1BgkVKx5WAmD3y+ioMZ2QT4eDLx7ihiGlS3uiwBOLjW7KS7aTrkZ5tt3gHmyKJ290ONhtbWJyJyFgosUmpSj2cz8It41u9Lx+P0dP53ajp/13HyqDmyaPUncGzPmfb6V5hPXRr3UCddEXEZCixSqrLzHDw1fQM/rj8IwANd6jHyuma4azp/1+F0ws4483XR9vkUzOniHwpR95orRvsFW1mhiIgCi5S+/53O/8qmgYy7szV+3uqM63KO7YHVn8HaL+HkEbPNzQOaXg/t7zeHSKuTrohYQIFFLpkf1x/kyWnrycl30jioMp/0b09YNXX0dEn5ObBllrl+0b4VZ9prNIZ290HkneBT1br6RKTCUWCRS2r9vnQGfrGa1OM5VKtk58N7omgfXs3qsuR8kjeZ/Vw2fAe5WWabhw9E3GqGl9C2euoiIqVOgUUuuUMZpxj4xWo2HcjE093GqJtbcnu7MKvLkn+Tcxw2TIVVn0Lq5jPtIZFmcIm4DbwqW1efiJRrCixiiZO5+Tw5bT1zNiYD8GDX+jzTo6k645YFhgH7VsLqT825XRw5ZrvdD1rdYc6mG9zS2hpFpNxRYBHLOJ0GY+O2826cOuOWWSeOwPpvzI66R3eeaa/dHqIGQIubNSGdiJQIBRax3N874zYKNDvj1qmuL7kyxek01y9a/Sls+wmc+Wa7dwC0utMcHh3U3NISRaRsU2ARl7Bhv9kZNyUzh6q+nrzfVzPjlllZqeaw6PjPIT3pTHtYtBlcWtwMnj6WlSciZZMCi7iM5IxsHvxyNRv2Z+DhZuOlXi3oG13X6rLkQjmdsGuhufjitjlgOMx2PXURkQugwCIu5X9nxu0XU5fnr2+Op7ubxZXJRTmebD51WfMFpO890167A0T1P93XRQtkisi5KbCIyzEMg/cX7WTMvAQAOjWozoS72lK1kt3iyuSiFTx1mQwJc870dfHyN1eMjupvDpMWEfkfCizisuZvTmbY1HWczHVQt7ovk/q1o3GQn9VlSUk5nmKOMIr/HI7tPtMe0tpcv6jl7eCt/0dFxKTAIi5tW3ImD3y+mv3HTlHJ7s64O9sQ2zzI6rKkJP01wmjN57D1R3Dkmu2evuarorb9zA67mk1XpEJTYBGXd/RELo9+Hc/yXUex2eDJa5rw6OUNsOkLrPw5cQQ2TDGfuqQlnGmv0cQMLpF3QqUa1tUnIpYp6vf3BfV4nDBhAuHh4Xh7exMdHc3KlSvPe3x6ejqDBg0iJCQELy8vGjduzJw5cwr2jx49mvbt2+Pn50dgYCA33XQTCQkJ57milAfVKtn58v5o7ulYF8OAMfMSGPztWk7lOqwuTUpapeoQMwgGrYD75kPrvuaTlrQEmP8cvNUUvusPO+LMJzMiIv+j2E9Ypk6dSr9+/Zg4cSLR0dGMHTuWadOmkZCQQGBg4D+Oz83NpXPnzgQGBvLss88SGhpKUlISVapUITLS7ITXo0cP7rzzTtq3b09+fj7PPvssmzZtYsuWLVSqVLQRBnrCUrZ9s2IvL8zaRL7ToEUtfz7q147QKprTo1zLzoBN35sjjA6uPdMeEGYGmjZ9oUod6+oTkUui1F4JRUdH0759e9577z0AnE4nYWFhDB48mBEjRvzj+IkTJzJmzBi2bduGp2fRpmY/fPgwgYGBLF68mK5duxbpHAWWsm/FriM88vUajp7IpXolOx/cHUWHelrxuUI4tMEcHr1hqhlkALBBgyugzT3QtCd4eFlaooiUjlJ5JZSbm0t8fDyxsbFnLuDmRmxsLMuWLTvrObNnzyYmJoZBgwYRFBREREQEo0aNwuE492P/jAzzF1a1avqyqkii61dn9mOdaR7iz5ETufT9eDnfrNj77ydK2RfSCq4bA08kwC0fQ72ugAE7f4PpA+CtJvDLM5C80epKRcQixQosaWlpOBwOgoIKj+YICgoiOTn5rOfs2rWL6dOn43A4mDNnDs8//zxvvfUWr7766lmPdzqdDBs2jM6dOxMREXHOWnJycsjMzCy0SdlXu6ov0x+JoWerEPIcBs/O3MhzMzeSm69+DRWCpw+0uh36/whD1sJlT4JfLTh1DFZMhIld4MNusHKS2SYiFUapTzPqdDoJDAzko48+Iioqit69e/Pcc88xceLEsx4/aNAgNm3axJQpU8573dGjRxMQEFCwhYWFlUb5YgFfuwfv9WnDU92bYLPB1yv2cvfHKzh8PMfq0uRSqlYfrnoeHt8EfadD817g5gmH1sGcJ82Out8/ALsWqaOuSAVQrMBSo0YN3N3dSUlJKdSekpJCcHDwWc8JCQmhcePGuLu7F7Q1a9aM5ORkcnNzCx372GOP8dNPP7Fw4UJq16593lpGjhxJRkZGwbZv377ifBRxcTabjUFXNGTSPe2o7OXByj1HufG9JWzcn/HvJ0v54uYOja6GO76AJ7ZB99EQ2Bzys2HjNPiiF4yLhIWj4Ngeq6sVkVJSrMBit9uJiooiLi6uoM3pdBIXF0dMTMxZz+ncuTM7duzA+be/ASUmJhISEoLdbk7JbhgGjz32GDNnzuS3336jXr16/1qLl5cX/v7+hTYpf2KbB/HDoM7Ur1GJQxnZ3DZxKT+sPWB1WWKVSjUg5lF4ZCkMXAjt7gevAMjYC4vfMIPL5Oth3beQe8LqakWkBF3QsOb+/fvz4Ycf0qFDB8aOHct3333Htm3bCAoKol+/foSGhjJ69GgA9u3bR4sWLejfvz+DBw9m+/bt3HfffQwZMoTnnnsOgEcffZRvvvmGWbNm0aRJk4KfFRAQgI9P0Ya2apRQ+ZZxKo9hU9ayMOEwAA90qceIa5viocUTJe8UbPsZ1n5lvh7i9K80ux+0uAna3K0ZdUVcWKnOdPvee+8xZswYkpOTad26Ne+++y7R0dEAXH755YSHhzN58uSC45ctW8bjjz/OunXrCA0N5f777+eZZ54peE10rplNP/vsM+69994i1aTAUv45nAZvL0hgwsKdAHRuWJ33+mjxRPmb9H2w/ltY93Xh10PVGkDrPtDqTqii/m4irkRT80u5NWfjIZ6ctp6TuQ5qV/Xho3va0byW/p3L3xgGJC2Fdd/A5pmQ99frIRvU72ZOTNf0erD7WlqmiCiwWF2OlLKE5OM8+OVqko6cxNvTjf/eFsmNkbWsLktcUU4WbJllPnnZ88eZ9r9eGbW+C+rE6JWRiEUUWKTcyziZx+Apa/k90ezX8lDX+jzVvYn6tci5HdsD66eYT17Sk860Vw2HyD7mIoxVwy0qTqRiUmCRCsHhNBgzL4GJi81+LV0a1mB8nzbq1yLn53TC3mVmcNnyA+RmndlXt4sZXFrcBF5+VlUoUmEosEiF8tOGgzw1bQOn8hyEVfPhw7vVr0WKKPcEbP0J1n8DuxZTMMrIwwea3WB21q3XzZwPRkRKnAKLVDhbD2Xy0Jfx7D1q9mt549ZW9GodanVZUpZk7DcXYFz3LRzZfqbdLwRa3WG+NgpsZl19IuWQAotUSOkncxkyZV1BvxbN1yIXxDDgQLzZUXfjdMhOP7MvJNIMLhG3QeWalpUoUl4osEiF5XAavDk/gQ8Wmf1aYupX57272lC9spfFlUmZlJ8DifPMzrrb54Ez32y3uUPDWIjsDU2uMxduFJFiU2CRCu+X0/O1nMh1UCvAm4n3RNGqdhWry5Ky7MQR2PQ9bJhiPoH5i5e/uThj5J1QpxO46YmeSFEpsIgA21OO8+CX8exOO4Hdw41Xb4rgjnaa6VRKwOFEs7/Lhu/MtYz+EhAGLW+HVr0hsKl19YmUEQosIqdlZucxfOo6ft2aCkDf6Dq8eEML7B76W7CUgL+GSG+YAptnQc7fVhQPiTSDS8St4Hf2Fe1FKjoFFpG/cToNJizcwdu/JmIY0KZOFT7oG0VwgLfVpUl5kpcNib+YT122z/9bfxc3c2h0q97Q7HrN7yLyNwosImexcFsqQ6esJTM7nxqV7Uy4qy3R9atbXZaURyeOwJaZZnjZt+JMu4cPNO1pDpNucCW4e1pXo4gLUGAROYekIyd46Mt4tiUfx93Nxshrm3J/l3rnXDVc5KId3WUOj94wFY7sONPuWx1a3Awt74CwDlrPSCokBRaR8ziZm8+zMzbyw7qDAFzfKoQ3bm1FJS8PiyuTcs0w4OAa86nLpu/hxOEz+6rUhZa3meFFnXWlAlFgEfkXhmHw+dI9vPrzVvKdBo2DKjPx7ijq16xsdWlSETjyYfci2DANtv1UeD2j4JbmSKOI2yBAszVL+abAIlJEq/cc5dGv15B6PIfKXh68eXskPSI0okMuodyTkDDHfG20Y8GZzrrYoG5naHkrNL8JfKtZWaVIqVBgESmG1OPZPPb1WlbuOQrAw90a8OQ1jTWlv1x6J4+aK0hvmAZ7l55pd/MwZ9aNuA2aXAteehIo5YMCi0gx5TmcvP7LNj5Zshswp/R/t08bavppSn+xSPo+2DwDNk6D5I1n2j19zdDS8nZocBV42K2rUeQiKbCIXKCfNhzk6ekbOJnrIMjfi/f7RhFVt6rVZUlFl7oNNk03Xxsd232m3bsKNL/RfPIS3gXc3C0rUeRCKLCIXIQdqcd56Mt4dh4+gYebjf/0bEb/TuEa+izWMww4sMYML5tmQFbymX2Vg8xh0hG3Qe12GiYtZYICi8hFysrJ5+np65mz0fxCuDGyFqNvaamhz+I6nA5I+tN86rJlFmSnn9lXpQ60uMUcKh0UofAiLkuBRaQEGIbBp3/uYfQcc+hzo8DKfHB3FA0D1eFRXEx+LuxaaIaXhDmFh0nXaGyuZ9TiFqjZ2LoaRc5CgUWkBK3ac5RBp4c+V7K788Ztrbi+VS2ryxI5u9yT5lpGm6ZD4nxw5JzZF9QSIm42w0u1etbVKHKaAotICUs9ns3gb9ayYrc59HlA53BGXttMqz6La8vONJ+4bJoBO+P+NscLUKstRNxi9nsJqG1djVKhKbCIlIJ8h5M35ycycfFOANrWqcKEvm0JCfCxuDKRIjh5FLb+aC4LsOcPMJxn9oV1NMNL817gp4kT5dJRYBEpRQu2pDD8u3Ucz86nWiU74+5szWWNalpdlkjRZaWaHXU3zYC9y4C/vgpOz64bcTM06wWV9d+1lC4FFpFStvfISR75Op7NBzOx2WDYVY0ZfGVD3Nw0GkPKmMyDsPkH2DwT9q88025zg/DLzFdGzW6EStUtK1HKLwUWkUsgO8/BSz9u5tuV+wC4rFENxvZuTfXKmh1Xyqj0vafDyww4uPZMu80d6nU9HV5u0LpGUmIUWEQuoe/j9/PcDxvJznMS7O/NhL5tiKqrX+hSxh3bc+bJy6F1Z9pt7lC/m7kgo8KLXCQFFpFLLCH5OI98Hc+u07Pjjri2Kfd3qafZcaV8OLrLDC6bf4DkDWfaC5683ARNb9BrIyk2BRYRC2Tl5DPi+w38tOEQAN1bBPHf2yIJ8PG0uDKREnRkp7mi9OaZhRdltLlDvcvOPHmpVMOqCqUMKer39wVNIDFhwgTCw8Px9vYmOjqalStXnvf49PR0Bg0aREhICF5eXjRu3Jg5c+Zc1DVFXFFlLw/G92nDK71aYHd3Y97mFK4f/wcb92dYXZpIyaneAC57Ah5eAoPXwFUvQHArMBywaxH8NAzebASf3wCrPjFHJIlcpGI/YZk6dSr9+vVj4sSJREdHM3bsWKZNm0ZCQgKBgYH/OD43N5fOnTsTGBjIs88+S2hoKElJSVSpUoXIyMgLuubZ6AmLuJoN+9N59Os17D92Cru7G89f34y7O9bVKyIpv/568rJlFhxaf6bd5mYOlW7eC5peD/4hlpUorqfUXglFR0fTvn173nvvPQCcTidhYWEMHjyYESNG/OP4iRMnMmbMGLZt24an59kfixf3mmejwCKuKONkHk9MW8+vW1MAuL5VCKNvaYmft14RSTl3dLcZXLb8UHi0ETao09EML81u0Ay7UjqBJTc3F19fX6ZPn85NN91U0N6/f3/S09OZNWvWP8657rrrqFatGr6+vsyaNYuaNWty11138cwzz+Du7n5B1wTIyckhJ+fM+hiZmZmEhYUpsIjLMQyDj//YzRtzt5HvNKhXoxLv3dWGFrUCrC5N5NI4lmTOsLtlVuF5XgBC20HzG815XrS2UYVUKn1Y0tLScDgcBAUFFWoPCgoiOTn5rOfs2rWL6dOn43A4mDNnDs8//zxvvfUWr7766gVfE2D06NEEBAQUbGFhYcX5KCKXjM1mY2DX+kx9KIZaAd7sTjvBze8v5esVSZSTPu8i51e1LnR6DB5YAI9vgR5vmK+IsMGB1bDgBXi3NUy8DH4fA4cTrK5YXFCpr9rmdDoJDAzko48+Iioqit69e/Pcc88xceLEi7ruyJEjycjIKNj27dtXQhWLlI6oulX5echlXNk0kNx8J8/N3MSQKes4np1ndWkil05AKHR8GAbMgScSoOdb5rBom7s5XPq3V2FCB3ivg/nPhzaAgr0AHsU5uEaNGri7u5OSklKoPSUlheDgsy+WFRISgqenJ+7u7gVtzZo1Izk5mdzc3Au6JoCXlxdeXppNVMqWqpXsfNyvHZP+2MV/5yXw4/qDbDqQoVdEUjH5BUH7B8ztxBFI+Bm2zDZHGqUlmE9bfh8DVcPN/i7NekFoFLhphfSKqFj/1u12O1FRUcTFxRW0OZ1O4uLiiImJOes5nTt3ZseOHTidZ1YFTUxMJCQkBLvdfkHXFCnL3NxsPNStAd891LHQK6Ivl+sVkVRglapD235w93R4agfc/JE5osjDx5xxd+l4+CQW3mkOPz8JuxaDI9/qquUSuqBhzf379+fDDz+kQ4cOjB07lu+++45t27YRFBREv379CA0NZfTo0QDs27ePFi1a0L9/fwYPHsz27du57777GDJkCM8991yRrlkUGiUkZdGxE7k8NX09v24156no2TKE0be2xF+jiERMuSdgx69mp92EuZB7/Mw+n2rQ5Frz6Uv9K8DT27o65YIV9fu7WK+EAHr37s3hw4d54YUXSE5OpnXr1sydO7cgWOzduxe3vz2uCwsLY968eTz++OO0atWK0NBQhg4dyjPPPFPka4qUV1Ur2ZnUrx2fLNnN679s4+eNh9h4IIPxfdoQGVbF6vJErGevZA6Bbt4L8nPMJytbZ0PCHDh5BNZ9bW72ytAw1gwvja4Bb/3FtbzR1PwiLmLt3mMM/nYt+4+dwtPdxohrm3Ff53BNNCdyNo582LsUtv4E236CzANn9rl5moszNr0emvaEykWbgFSsobWERMqgjFN5PDN9A3M3m0P6Y5sFMua2SKpWsltcmYgLMww4uMYML1t/hCPb/7bTBmHRZnBpdj1Uq29ZmXJ2CiwiZZRhGHy1PIlXftpKrsNJSIA34+5sQ4d61awuTaRsOJxgBpdtP/3PLLtAYIsz4SW4FegJpuUUWETKuM0HMxj8zVp2pZ3AzQaPxzbm0Ssa4u6mX7AiRZaxH7bNMcPLniXmAo1/CQgzw0vTnlCnE7gXu1unlAAFFpFyICsnnxd+2MSMteb7+U4NqjO2d2sC/TUaQqTYTh6F7fPNpy874iD/1Jl93lWgcQ9oeh00uAq8KltWZkWjwCJSjkyP38/zP2ziVJ6D6pXsvHVHJJc3UUdCkQuWe9KcoG7bz5D4izni6C/uXqc77faExteaE9xJqVFgESlndqRm8dg3a9iWbM5D8WDX+jx5TRPsHpr1U+SiOB2wb4UZXrb9DMd2/22nDWq3gybXmQGmRmP1eylhCiwi5VB2noNRc7byxbIkACJrBzC+T1vqVPe1uDKRcsIwIHWruUzAtjnm6KO/q9bAnKyuyXXm6CP1e7loCiwi5djcTck88/0GMk7l4eflwWu3tOTGyFpWlyVS/mQehIRfzInqdv8Ojtwz+3yqQePuZoBRv5cLpsAiUs4dSD/F0G/XsjrpGAC3R9XmpV4t8LXrb3wipSLnuNlZN+EX2D4PTh07s8/dDvW6meGlcQ9zVWopEgUWkQog3+Hk3bjtjF+4A8OA+jUrMb6PVn4WKXWOfNi7DBLnnqXfCxASab42atzD/Gf1ezknBRaRCmTZziM8PnUdyZnZ2N3dGHldU+7tpGn9RS4Jw4C0RPO10bY5sH8V8LevVr9ap18dXQf1umqRxv+hwCJSwRw9kcvT0zfw69YUAK5sGsiY21pRvbKXxZWJVDBZh835XhLmwM6FkHfizD5PX3Nl6cbdzc0v2Lo6XYQCi0gFZBgGXyxL4rU5W8nNd1LTz4t37mhNl0Y1rC5NpGLKy4Y9f5j9XhLnFl6kEaBWG3Oul8bdK+yrIwUWkQps66FMhny7lu2pWdhs5pwtT1ytOVtELGUYkLzRDC6Jc+FAfOH9fiGnn7z0MDvw2ivGdAUKLCIV3KlcB6/8vIVvVuwFoFXtAMbd2YZ6NSpZXJmIAHA8xXx1lDj3n6+OPLzN/i6NrjFDTJU61tVZyhRYRASAuZsO8cz3G8k4lYev3Z2Xe0Vwa9tQdcgVcSV52ZC0BBLnQcJcyNhbeH9gczO4NOoOtduXqwnrFFhEpMDB9FM8PnUdK3YfBeCGyFq8elMEAT6eFlcmIv/w12y72+eZAWbfCjCcZ/Z7V4GGsWaAaRgLvtUsK7UkKLCISCEOp8HExTt5e0EiDqdBaBUfxt3ZmnbhZfuXnUi5d/Io7PjVDC87foXs9DP7bG7mE5e/Xh0FRZS5jrsKLCJyVmv3HmPolHXsPXoSNxs8dmUjhlzZEA93dcgVcXmOfHOel+3zIHE+pG4uvN8/FBpdbQaYet3KxHIBCiwick7Hs/N4cfZmZqwxh1i2rVOFsb3baBFFkbImfZ/ZcXf7fNi1GPJPndnnboe6nc3w0ugaqNHQujrPQ4FFRP7VrHUH+M8PmzienU9lLw9e7tWCm9uoQ65ImZR3Cvb8eTrAzINjewrvr1rvTHgJ7wyePpaU+b8UWESkSPYfO8njU9exao+5kNuNkbV4RR1yRco2w4AjO8x+L9vnQ9JScOad2e/hc3rY9NXmVjXcslIVWESkyPIdTt5ftJNxcdsLOuS+07s1HeqpQ65IuZBz3HxltGOB2ffl+MHC+6s3MoNLw1jzNdIlXO9IgUVEim3t3mMMm7qOpCNmh9xHLm/AsNjGeKpDrkj5YRiQugW2LzC3fcvBmX9mv6cvhF9mhpdGsVCtfqmWo8AiIhckKyefl2ZvZlr8fgAiawfwTu/W1K/p+qMNROQCZGfArkVmeNnxKxw/VHh/tQanw8vVZpAp4acvCiwiclF+3nCIZ2eaM+T6eLrz/PXN6dMhTB1yRcozw4CUzearo+2//vPpy8NLILhlif5IBRYRuWiHMk7xxHfrWbrzCACxzYJ449aWVK/sZXFlInJJZGfC7sXm05eUTfBAXIlPTKfAIiIlwuk0+GTJbsbMSyDX4aRGZS/G3N6KK5oEWl2aiJQDRf3+Vk86ETkvNzcbA7vW54dBnWkUWJm0rBwGfLaK53/YxKlch9XliUgFocAiIkXSvJY/Pw7uwoDO4QB8uTyJnuP/YOP+DGsLE5EKQYFFRIrM29OdF29owRf3dSDQz4tdh09w8/t/MmHhDhzOcvF2WURc1AUFlgkTJhAeHo63tzfR0dGsXLnynMdOnjwZm81WaPP2LjwkKisri8cee4zatWvj4+ND8+bNmThx4oWUJiKXQNfGNZk3rCvXRgST7zQYMy+B3h8uY++Rk1aXJiLlVLEDy9SpUxk+fDgvvvgia9asITIyku7du5OamnrOc/z9/Tl06FDBlpSUVGj/8OHDmTt3Ll999RVbt25l2LBhPPbYY8yePbv4n0hELomqley837ctb94eSWUvD1YnHePacb/z3ep9lJO+/CLiQoodWN5++20GDhzIgAEDCp6E+Pr68umnn57zHJvNRnBwcMEWFBRUaP/SpUvp378/l19+OeHh4Tz44INERkae98mNiFjPZrNxW1Rtfhl6GR3Cq3Ei18HT0zfw8FfxHMnKsbo8ESlHihVYcnNziY+PJzY29swF3NyIjY1l2bJl5zwvKyuLunXrEhYWRq9evdi8eXOh/Z06dWL27NkcOHAAwzBYuHAhiYmJXHPNNee8Zk5ODpmZmYU2EbFGWDVfvn2wIyOubYqnu415m1PoPvYP4ramWF2aiJQTxQosaWlpOByOfzwhCQoKIjk5+aznNGnShE8//ZRZs2bx1Vdf4XQ66dSpE/v37y84Zvz48TRv3pzatWtjt9vp0aMHEyZMoGvXruesZfTo0QQEBBRsYWFhxfkoIlLC3N1sPNytAT8M6kyTID/SsnK4//PVjJyxgRM5+f9+ARGR8yj1UUIxMTH069eP1q1b061bN2bMmEHNmjX58MMPC44ZP348y5cvZ/bs2cTHx/PWW28xaNAgfv3113Ned+TIkWRkZBRs+/btK+2PIiJF0KJWALMe68zAy+phs8G3K/dx7bg/WL3nqNWliUgZ5lGcg2vUqIG7uzspKYUf86akpBAcHFyka3h6etKmTRt27NgBwKlTp3j22WeZOXMmPXv2BKBVq1asW7eON998s9Drp7/z8vLCy0vTg4u4Im9Pd57r2Zwrmgby5Hfr2Xv0JHd8uIyHujXg8djG2D00o4KIFE+xfmvY7XaioqKIi4sraHM6ncTFxRETE1OkazgcDjZu3EhISAgAeXl55OXl4eZWuBR3d3ecTmdxyhMRF9OpQQ3mPt6VW9qG4jTgg0U76TXhT7Ylq8+ZiBRPsf+aM3z4cCZNmsTnn3/O1q1beeSRRzhx4gQDBgwAoF+/fowcObLg+Jdffpn58+eza9cu1qxZw913301SUhIPPPAAYA557tatG0899RSLFi1i9+7dTJ48mS+++IKbb765hD6miFjF39uTt+9ozcS721Ktkp2thzK5cfyffLh4pyabE5EiK9YrIYDevXtz+PBhXnjhBZKTk2ndujVz584t6Ii7d+/eQk9Ljh07xsCBA0lOTqZq1apERUWxdOlSmjdvXnDMlClTGDlyJH379uXo0aPUrVuX1157jYcffrgEPqKIuIIeESG0rVuVkd9vJG5bKqN/2Ubc1lTevD2SOtV9rS5PRFycVmsWkUvKMAy+W72Pl3/cwolcB752d/7Tszl9OoRhK+Fl60XE9Wm1ZhFxSTabjd7t6zB3WFc61KvGyVwHz87cyIDJq0jJzLa6PBFxUQosImKJsGq+TBnYkf/0bIbdw41FCYe55p3fmbXugKb2F5F/UGAREcu4udl44LL6/Dy4CxGh/mScymPolHU89s1ajp7Itbo8EXEhCiwiYrlGQX7MfLQzw2Ib4eFm4+eNh7jmncUs2KKp/UXEpMAiIi7B092NYbGNmfloZxoFViYtK5eBX6zmyWnryczOs7o8EbGYAouIuJSWtQP4cXAXHuxaH5sNpsfvp/s7v/PH9sNWlyYiFlJgERGX4+3pzrPXNWPaQzGEV/flUEY293yykv/8sFELKYpUUAosIuKy2oVXY87Qy+gfUxeAr5bvpce431m+64jFlYnIpabAIiIuzdfuwUu9Ivj6gWhCq/iw7+gp7vxoOS/9uJlTuQ6ryxORS0SBRUTKhM4NazB32GXc2T4MgM/+3MN17/5BfNJRiysTkUtBgUVEygw/b09ev7UVkwe0J9jfm91pJ7ht4jJe+3kL2Xl62iJSnimwiEiZc3mTQOY93pVb2oZiGDDpj91c9+4frNl7zOrSRKSUKLCISJkU4OPJ23e05uN+7Qj082LX4RPc9sFSRv+yVU9bRMohBRYRKdNimwcx//Gu3NwmFKcBHy7exfXjl7BuX7rVpYlICVJgEZEyr4qvnXd6t2ZSv3bU9PNiR2oWt7z/J6//sk1PW0TKCQUWESk3rm4exILHu3JT61o4DZi4eCc93/2DterbIlLmKbCISLlSxdfO2Dvb8NE9UdSo7MXOwye49YOljJ6jvi0iZZkCi4iUS9e0CObX4Weetnz4+y6uG6d5W0TKKgUWESm3/nraMumvkUSn52155actmiVXpIxRYBGRcs/s29KNW9vWxjDgkyW7uXbc76zQmkQiZYYCi4hUCAG+nrx1RySfnZ4ld8+Rk/T+aDkvztqkFaBFygAFFhGpUK5oEsj84V3p08Fck+jzZUl0H/s7S7anWVyZiJyPAouIVDj+3p6MvqUVX91vrgC9/9gp7v5kBSO+30Bmdp7V5YnIWSiwiEiF1aVRDeY/3pV+MXUBmLJqH9e8/TtxW1MsrkxE/pcCi4hUaJW8PHi5VwRTHuxIeHVfkjOzuf/z1QybspZjJ3KtLk9ETlNgEREBOtavzi9Du/Jg1/q42eCHdQe5+p3F/LzhEIZhWF2eSIWnwCIicpqP3Z1nr2vGjEc70zioMmlZuQz6Zg0PfxVPama21eWJVGgKLCIi/6N1WBV+HNyFIVc1wsPNxrzNKcS+vZhpq/fpaYuIRRRYRETOwsvDneFXN2b2Y11oGRpAZnY+T03fQL9PV7Lv6EmryxOpcBRYRETOo3ktf2Y+2okR1zbF7uHGH9vT6D72dyb/uRunU09bRC4VBRYRkX/h4e7Gw90aMHfoZXQIr8bJXAf/9+MWbv9wGTtSj1tdnkiFcEGBZcKECYSHh+Pt7U10dDQrV64857GTJ0/GZrMV2ry9vf9x3NatW7nxxhsJCAigUqVKtG/fnr17915IeSIipaJ+zcpMebAjr9wUQSW7O/FJx7hu3BLGx20nN99pdXki5VqxA8vUqVMZPnw4L774ImvWrCEyMpLu3buTmpp6znP8/f05dOhQwZaUlFRo/86dO+nSpQtNmzZl0aJFbNiwgeeff/6swUZExEpubjbu6ViX+cO7cUWTmuQ6nLy1IJEb31vC+n3pVpcnUm7ZjGJ2eY+OjqZ9+/a89957ADidTsLCwhg8eDAjRoz4x/GTJ09m2LBhpKenn/Oad955J56ennz55ZfFq/5vMjMzCQgIICMjA39//wu+johIURmGwax1B3npx80cO5mHmw3u61yP4dc0xtfuYXV5ImVCUb+/i/WEJTc3l/j4eGJjY89cwM2N2NhYli1bds7zsrKyqFu3LmFhYfTq1YvNmzcX7HM6nfz88880btyY7t27ExgYSHR0ND/88MN5a8nJySEzM7PQJiJyKdlsNm5qE8qvw7txU+taOA34eMluLaYoUgqKFVjS0tJwOBwEBQUVag8KCiI5Ofms5zRp0oRPP/2UWbNm8dVXX+F0OunUqRP79+8HIDU1laysLF5//XV69OjB/Pnzufnmm7nllltYvHjxOWsZPXo0AQEBBVtYWFhxPoqISImpXtmLsXe24bN721MrwJt9R83FFJ+ctl7T+4uUkGK9Ejp48CChoaEsXbqUmJiYgvann36axYsXs2LFin+9Rl5eHs2aNaNPnz688sorBdfs06cP33zzTcFxN954I5UqVeLbb78963VycnLIyckp+HNmZiZhYWF6JSQilsrKyefNeQl8vmwPhgE1Ktt58YYWXN8qBJvNZnV5Ii6nVF4J1ahRA3d3d1JSCq9kmpKSQnBwcJGu4enpSZs2bdixY0fBNT08PGjevHmh45o1a3beUUJeXl74+/sX2kRErFbZy4P/u7EF0x/uRKNAc3r/wd+u5f7PV3Mg/ZTV5YmUWcUKLHa7naioKOLi4granE4ncXFxhZ64nI/D4WDjxo2EhIQUXLN9+/YkJCQUOi4xMZG6desWpzwREZcRVbcqPw3pwrDYRni62/htWyrXvL2Yz/7cjUMTzokUW7G7sQ8fPpz+/fvTrl07OnTowNixYzlx4gQDBgwAoF+/foSGhjJ69GgAXn75ZTp27EjDhg1JT09nzJgxJCUl8cADDxRc86mnnqJ379507dqVK664grlz5/Ljjz+yaNGikvmUIiIW8PJwZ1hsY3q2DGHkjI2sTjrGSz9uYda6g7x+a0uaBuvJsEhRFTuw9O7dm8OHD/PCCy+QnJxM69atmTt3bkFH3L179+LmdubBzbFjxxg4cCDJyclUrVqVqKgoli5dWugV0M0338zEiRMZPXo0Q4YMoUmTJnz//fd06dKlBD6iiIi1GgX58d1DMXyzci9v/LKNdfvSuf7dJTzUrT6Dr2yEt6e71SWKuLxiz8PiqjQPi4iUBckZ2bwwaxPzt5h9AevVqMRrN0fQqUENiysTsUapdLoVEZGLExzgzUf92jHx7iiC/L3YnXaCuyat4Klp60k/qSHQIueiwCIiYoEeEcEsGN6NuzvWAWBa/H6uemsxs9YdoJw8+BYpUQosIiIW8ff25NWbWjL94RgaBVbmyIlchk5ZR79PV7L3yEmryxNxKQosIiIWaxdejZ+HXMaT1zTG7uHGH9vTuGbsYj5YtJM8h1aBFgEFFhERl2D3cOOxKxsxd+hlxNSvTnaekzfmbuOG8UtYs/eY1eWJWE6BRUTEhdSvWZlvBkbz5u2RVPX1ZFvycW79YCnP/7CJzOw8q8sTsYwCi4iIi7HZbNwWVZu4Jy7n1ra1MQz4cnkSsW8tZs7GQ+qUKxWSAouIiIuqVsnOW3dE8s3AaOrVqETq8Rwe/XoN93++mn1H1SlXKhYFFhERF9epQQ1+GXoZQ65seGZdond+58PF6pQrFYcCi4hIGeDt6c7wa5rwy9CudKhXjVN5Dkb/YnbKjU9Sp1wp/xRYRETKkIaBlZn6YEfG3NaqoFPubROX8uzMjWScVKdcKb8UWEREyhibzcbt7cKIe+JybosyO+V+s2IvV729SDPlSrmlwCIiUkZVq2TnzdsjmfJgRxrUrERaljlT7j2frGR32gmryxMpUQosIiJlXMf61fllaFeevKYxXh5uLNmRRvexvzP210Sy8xxWlydSIhRYRETKgb9myp3/eFe6Nq5Jbr6Tsb9u59pxf7Bke5rV5YlcNAUWEZFypG71Snw+oD0T7mpLoJ8Xu9NOcPcnKxjy7VpSM7OtLk/kgimwiIiUMzabjZ6tQoh7ohv3dgrHzQaz1x/kqrcW8/nSPTic6pQrZY/NKCfdyTMzMwkICCAjIwN/f3+ryxERcRkb92fwnx82sn5/BgARof68dlNLIsOqWFuYCEX//tYTFhGRcq5l7QBmPNqZV3q1wM/bg00HMrnp/T/5zw+au0XKDgUWEZEKwN3Nxj0x4cQ90Y2bWtfCMOCr5ebcLTPW7NfcLeLy9EpIRKQCWrozjed/2MTOw+Z8LdH1qvHqTRE0CvKzuDKpaPRKSEREzslcULErT/dogrenGyt2H+XacX8w+petnMjJt7o8kX9QYBERqaDsHm48enlDfh3ejaubB5HvNPhw8S6ufnsxczcd0msicSkKLCIiFVztqr5M6teOT/q3o3ZVHw5mZPPwV2u497NV7NEU/+IiFFhERASAq5oFseDxbgy+siF2dzcWJx7mmrG/8/YCTfEv1lNgERGRAj52d564pglzh13GZY1qkJvv5N247Vz9zmJ+25ZidXlSgSmwiIjIP9SvWZkv7uvAhLvaEuzvzb6jp7hv8moe+Hw1+46etLo8qYAUWERE5Kz+PsX/Q13r4+Fm49etKcS+vZjxcdv1mkguKc3DIiIiRbI95TjPz9rE8l1HAQiv7sv/3diCy5sEWlyZlGWah0VEREpUoyA/vh3YkXF3tibQz4s9R05y72erePALvSaS0ndBgWXChAmEh4fj7e1NdHQ0K1euPOexkydPxmazFdq8vb3PefzDDz+MzWZj7NixF1KaiIiUIpvNRq/WocQ90Y0HutTD3c3G/C0pXP2OXhNJ6Sp2YJk6dSrDhw/nxRdfZM2aNURGRtK9e3dSU1PPeY6/vz+HDh0q2JKSks563MyZM1m+fDm1atUqblkiInIJ+Xl78p/rmzNnyGVE16tGdp6TtxYk0mPs7yxMOPf3gciFKnZgefvttxk4cCADBgygefPmTJw4EV9fXz799NNznmOz2QgODi7YgoKC/nHMgQMHGDx4MF9//TWenp7FLUtERCzQJNiPKQ8Wfk004LNVGk0kJa5YgSU3N5f4+HhiY2PPXMDNjdjYWJYtW3bO87Kysqhbty5hYWH06tWLzZs3F9rvdDq55557eOqpp2jRokUxP4KIiFjp76+JBl5Wr9Boonc06ZyUkGIFlrS0NBwOxz+ekAQFBZGcnHzWc5o0acKnn37KrFmz+Oqrr3A6nXTq1In9+/cXHPPGG2/g4eHBkCFDilxLTk4OmZmZhTYREbGOn7cnz/Vszi9DL6NTg+rk5DsZF7ed2LcXM39zstYmkotS6qOEYmJi6NevH61bt6Zbt27MmDGDmjVr8uGHHwIQHx/PuHHjCjrnFtXo0aMJCAgo2MLCwkrrI4iISDE0CvLj6weimXBXW0ICvNl/7BQPfhnPgMmr2K21ieQCFSuw1KhRA3d3d1JSCk/PnJKSQnBwcJGu4enpSZs2bdixYwcAf/zxB6mpqdSpUwcPDw88PDxISkriiSeeIDw8/JzXGTlyJBkZGQXbvn37ivNRRESkFP190rlHL2+Ap7uNRQmH6f7O7/x37jZO5ORbXaKUMcUKLHa7naioKOLi4granE4ncXFxxMTEFOkaDoeDjRs3EhISAsA999zDhg0bWLduXcFWq1YtnnrqKebNm3fO63h5eeHv719oExER1+Jr9+DpHk2ZN6wr3RrXJNfh5P1FO7nqrcXMXn9Qr4mkyDyKe8Lw4cPp378/7dq1o0OHDowdO5YTJ04wYMAAAPr160doaCijR48G4OWXX6Zjx440bNiQ9PR0xowZQ1JSEg888AAA1atXp3r16oV+hqenJ8HBwTRp0uRiP5+IiLiA+jUrM3lAe37dmsrLP21m39FTDPl2LV8vT+L/bmxBsxD9pVPOr9iBpXfv3hw+fJgXXniB5ORkWrduzdy5cws64u7duxc3tzMPbo4dO8bAgQNJTk6matWqREVFsXTpUpo3b15yn0JERFyezWbj6uZBXNaoBh/9vov3F+1gxe6j9Hz3D+7pWJfhVzchwFfTWsjZaS0hERGxxP5jJxk1ZytzNpqjTKv6evJU96b0bh+Gu1vRB2FI2VbU728FFhERsdSfO9L4v9mb2Z6aBUBEqD8v3diCqLrVLK5MLgUFFhERKTPyHE6+XJbEO78mcjzbHEF0c5tQRlzblCD/c68/J2WfAouIiJQ5aVk5vDkvgamr92EY4Gt357ErG3J/l3p4ebhbXZ6UAgUWEREpszbsT+f/Zm9mzd50AOpW9+X5ns25qllgsSYZFdenwCIiImWa02nww7oDvP7LNlKP5wDQtXFNXri+OQ0DK1tcnZQUBRYRESkXsnLyGf/bdj5dsps8h4GHm43+ncIZGtsIf28Ngy7rFFhERKRc2Z12gtd+3sKvW1MBqF7JzlPdm3B7Ow2DLssUWEREpFxanHiYl3/czM7D5kKKEaH+vHhDC9qHaxh0WaTAIiIi5Vaew8nnS/cwLm57wTDo61uFMPK6ZoRW8bG4OikOBRYRESn3jmTl8Ob8RKas2othgLenGw91bcDD3RrgY9cw6LJAgUVERCqMzQczeOnHLazcfRSAkABvRlzblBsja2kYtItTYBERkQrFMAzmbExm1JytHEg/BUDbOlV48YYWRIZVsbY4OScFFhERqZCy8xx8/Mcu3l+0k5O5DgBuaRvKMz00zb8rUmAREZEKLSUzmzd+2caMtQcAc5r/Ry9vwAOX1cfbU/1bXIUCi4iICLBuXzov/3hmmv/QKj6MuLYp17cKUf8WF6DAIiIicpphGMxef5A3ftnGwYxsAKLqVuX565vTWv1bLKXAIiIi8j9O5Tr46PddTFy8k1N5p/u3tAnl6R5NCQ5Q/xYrKLCIiIicQ3JGNv+dt40Za8z+LT6e7jzYtT4PdauPr93D4uoqFgUWERGRf7F+Xzqv/LSF1UnHAAj29+ap7k24uU0oblqf6JJQYBERESmCv+ZvGf3LVvYfM+dvaVU7gP/0bE6HelqfqLQpsIiIiBRDdp6Dz/7cw4SFO8jKMdcnujYimBHXNqVu9UoWV1d+KbCIiIhcgLSsHN5ekMiUlXtxGuDpbqN/TDiDr2xEgK+n1eWVOwosIiIiFyEh+Tij5mxlceJhAKr4ejL0qkbc3bEunu5uFldXfiiwiIiIlIBFCamMmrOVxJQsAOrVqMTIa5tydfMgTTxXAhRYRERESki+w8nU1ft4Z0EiaVm5AETXq8Z/ejanZe0Ai6sr2xRYREREStjx7DwmLt7Jx3/sJiffCZgTzz3ZvQm1qvhYXF3ZpMAiIiJSSg6kn2LM3G38sO4gAF4ebtzfpR6PXN4AP291zC0OBRYREZFStmF/Oq/+vJWVu48CUL2SnWGxjbizQx11zC0iBRYREZFLwDAMFmxJ4fVftrEr7QQA9WtWYuS1zYhtFqiOuf9CgUVEROQSynM4+XblXsb+up2jJ8yOuR3qVeO565oRqRWhz0mBRURExAKZ2XlMXLSTT5ac6Zh7Y2QtnurehLBqvhZX53qK+v19QS/YJkyYQHh4ON7e3kRHR7Ny5cpzHjt58mRsNluhzdv7zBLeeXl5PPPMM7Rs2ZJKlSpRq1Yt+vXrx8GDBy+kNBEREUv5e3vydI+mLHzycm5pG4rNBrPXH+Sqtxbz6k9bSD+Za3WJZVKxA8vUqVMZPnw4L774ImvWrCEyMpLu3buTmpp6znP8/f05dOhQwZaUlFSw7+TJk6xZs4bnn3+eNWvWMGPGDBISErjxxhsv7BOJiIi4gFpVfHj7jtb8+FgXujSsQa7DycdLdtP1vwv56PedZOc5rC6xTCn2K6Ho6Gjat2/Pe++9B4DT6SQsLIzBgwczYsSIfxw/efJkhg0bRnp6epF/xqpVq+jQoQNJSUnUqVOnSOfolZCIiLiyxYmHGT1nK9uSjwMQWsWHJ65pzE2tQ3Fzq7gdc0vllVBubi7x8fHExsaeuYCbG7GxsSxbtuyc52VlZVG3bl3CwsLo1asXmzdvPu/PycjIwGazUaVKlXMek5OTQ2ZmZqFNRETEVXVrXJOfh1zGmNtaERLgzYH0Uwz/bj3Xj1/C76fXK5JzK1ZgSUtLw+FwEBQUVKg9KCiI5OTks57TpEkTPv30U2bNmsVXX32F0+mkU6dO7N+//6zHZ2dn88wzz9CnT5/zJq3Ro0cTEBBQsIWFhRXno4iIiFxy7m42bm8XxsInL+eZHk3x8/Jgy6FM+n26krs/XsGmAxlWl+iyivVK6ODBg4SGhrJ06VJiYmIK2p9++mkWL17MihUr/vUaeXl5NGvWjD59+vDKK6/8Y9+tt97K/v37WbRo0XkDS05ODjk5OQV/zszMJCwsTK+ERESkzDh6Ipf3ftvBl8v3kOcwv45val2LJ66pOCOKSuWVUI0aNXB3dyclJaVQe0pKCsHBwUW6hqenJ23atGHHjh2F2vPy8rjjjjtISkpiwYIF/xo6vLy88Pf3L7SJiIiUJdUq2XnhhubEDb+cXq1rAfDDOnNE0Ss/beHYCY0o+kuxAovdbicqKoq4uLiCNqfTSVxcXKEnLufjcDjYuHEjISEhBW1/hZXt27fz66+/Ur169eKUJSIiUqbVqe7LuDvb8NPgLnRuWJ1ch5NPTo8omrBwB6dyNaKo2MOahw8fzqRJk/j888/ZunUrjzzyCCdOnGDAgAEA9OvXj5EjRxYc//LLLzN//nx27drFmjVruPvuu0lKSuKBBx4AzLBy2223sXr1ar7++mscDgfJyckkJyeTm6tkKSIiFUdEaABf3R/NF/d1oHmIP8dz8hkzL4FuYxby7cq95DucVpdoGY/intC7d28OHz7MCy+8QHJyMq1bt2bu3LkFHXH37t2Lm9uZHHTs2DEGDhxIcnIyVatWJSoqiqVLl9K8eXMADhw4wOzZswFo3bp1oZ+1cOFCLr/88gv8aCIiImWPzWaja+OadGlYg9nrD/Lm/AT2HzvFyBkbmfTHLp7u3pTuLYIq3BpFmppfRETEheXkO/hq+V7e+207x07mAdCmThVG9GhKdP2y34VCawmJiIiUI5nZeUz6fRcf/7GbU6dnyb2iSU2e7tGUZiFl93tPgUVERKQcSs3M5t3ftvPtyn04nAY2G9zUOpThVzcuk0OhFVhERETKsd1pJ3hzfgI/bzgEgKe7jb7RdRl0RUNq+nlZXF3RKbCIiIhUABv3Z/Dfedv4Y3saAL52dx64rD4DL6uHn7enxdX9OwUWERGRCuTPHWn8d+421u83p/ev6uvJoCsacnfHunh7ultc3bkpsIiIiFQwhmEwd1MyY+YnsOvwCQBqBXgzLLYxt7QNxcO92NOvlToFFhERkQoq3+Hk+zX7eWfBdpIzswFoULMST1zThGsjgl1qDhcFFhERkQouO8/Bl8uSeH/RjoI5XFrVDuDJa5pwWaMaLhFcFFhEREQEgOPZeUz6Yzcf/7GLk6fXJepYvxpP92hK2zpVLa1NgUVEREQKScvKYcLCHXy9fC+5p9clim0WxFPdm9Ak2M+SmhRYRERE5Kz2HzvJu3HbmR6/H6dBweRzw2IbUbd6pUtaiwKLiIiInNeO1CzeXpDAnI3JAHi42bijfRhDrmxEcID3JalBgUVERESKZNOBDN6cn8CihMMAeHm40S+mLo9c3pBqleyl+rMVWERERKRYVu4+yph521i15xgAlezu3N+lHg90rY9/Kc2aq8AiIiIixWYYBosTD/Pm/AQ2HcgEIMDHk4e7NaB/p7r42j1K9OcV9fvb9aa8ExEREcvYbDYubxLIj4914YO+bWkYWJmMU3m8MXcbCcnHLaurZGOSiIiIlAs2m41rW4ZwTYtgZq07wLp96bSxcM4WBRYRERE5J3c3G7e0rc0tbWtbWodeCYmIiIjLU2ARERERl6fAIiIiIi5PgUVERERcngKLiIiIuDwFFhEREXF5CiwiIiLi8hRYRERExOUpsIiIiIjLU2ARERERl6fAIiIiIi5PgUVERERcngKLiIiIuLxys1qzYRgAZGZmWlyJiIiIFNVf39t/fY+fS7kJLMePHwcgLCzM4kpERESkuI4fP05AQMA599uMf4s0ZYTT6eTgwYP4+flhs9lK7LqZmZmEhYWxb98+/P39S+y68k+615eO7vWlo3t9ael+Xzolda8Nw+D48ePUqlULN7dz91QpN09Y3NzcqF27dqld39/fX//xXyK615eO7vWlo3t9ael+Xzolca/P92TlL+p0KyIiIi5PgUVERERcngLLv/Dy8uLFF1/Ey8vL6lLKPd3rS0f3+tLRvb60dL8vnUt9r8tNp1sREREpv/SERURERFyeAouIiIi4PAUWERERcXkKLCIiIuLyFFj+xYQJEwgPD8fb25vo6GhWrlxpdUll2ujRo2nfvj1+fn4EBgZy0003kZCQUOiY7OxsBg0aRPXq1alcuTK33norKSkpFlVcfrz++uvYbDaGDRtW0KZ7XbIOHDjA3XffTfXq1fHx8aFly5asXr26YL9hGLzwwguEhITg4+NDbGws27dvt7DissnhcPD8889Tr149fHx8aNCgAa+88kqhtWh0ry/M77//zg033ECtWrWw2Wz88MMPhfYX5b4ePXqUvn374u/vT5UqVbj//vvJysq6+OIMOacpU6YYdrvd+PTTT43NmzcbAwcONKpUqWKkpKRYXVqZ1b17d+Ozzz4zNm3aZKxbt8647rrrjDp16hhZWVkFxzz88MNGWFiYERcXZ6xevdro2LGj0alTJwurLvtWrlxphIeHG61atTKGDh1a0K57XXKOHj1q1K1b17j33nuNFStWGLt27TLmzZtn7Nixo+CY119/3QgICDB++OEHY/369caNN95o1KtXzzh16pSFlZc9r732mlG9enXjp59+Mnbv3m1MmzbNqFy5sjFu3LiCY3SvL8ycOXOM5557zpgxY4YBGDNnziy0vyj3tUePHkZkZKSxfPly448//jAaNmxo9OnT56JrU2A5jw4dOhiDBg0q+LPD4TBq1apljB492sKqypfU1FQDMBYvXmwYhmGkp6cbnp6exrRp0wqO2bp1qwEYy5Yts6rMMu348eNGo0aNjAULFhjdunUrCCy61yXrmWeeMbp06XLO/U6n0wgODjbGjBlT0Jaenm54eXkZ33777aUosdzo2bOncd999xVqu+WWW4y+ffsahqF7XVL+N7AU5b5u2bLFAIxVq1YVHPPLL78YNpvNOHDgwEXVo1dC55Cbm0t8fDyxsbEFbW5ubsTGxrJs2TILKytfMjIyAKhWrRoA8fHx5OXlFbrvTZs2pU6dOrrvF2jQoEH07Nmz0D0F3euSNnv2bNq1a8ftt99OYGAgbdq0YdKkSQX7d+/eTXJycqH7HRAQQHR0tO53MXXq1Im4uDgSExMBWL9+PUuWLOHaa68FdK9LS1Hu67Jly6hSpQrt2rUrOCY2NhY3NzdWrFhxUT+/3Cx+WNLS0tJwOBwEBQUVag8KCmLbtm0WVVW+OJ1Ohg0bRufOnYmIiAAgOTkZu91OlSpVCh0bFBREcnKyBVWWbVOmTGHNmjWsWrXqH/t0r0vWrl27+OCDDxg+fDjPPvssq1atYsiQIdjtdvr3719wT8/2O0X3u3hGjBhBZmYmTZs2xd3dHYfDwWuvvUbfvn0BdK9LSVHua3JyMoGBgYX2e3h4UK1atYu+9wosYplBgwaxadMmlixZYnUp5dK+ffsYOnQoCxYswNvb2+pyyj2n00m7du0YNWoUAG3atGHTpk1MnDiR/v37W1xd+fLdd9/x9ddf880339CiRQvWrVvHsGHDqFWrlu51OaZXQudQo0YN3N3d/zFiIiUlheDgYIuqKj8ee+wxfvrpJxYuXEjt2rUL2oODg8nNzSU9Pb3Q8brvxRcfH09qaipt27bFw8MDDw8PFi9ezLvvvouHhwdBQUG61yUoJCSE5s2bF2pr1qwZe/fuBSi4p/qdcvGeeuopRowYwZ133knLli255557ePzxxxk9ejSge11ainJfg4ODSU1NLbQ/Pz+fo0ePXvS9V2A5B7vdTlRUFHFxcQVtTqeTuLg4YmJiLKysbDMMg8cee4yZM2fy22+/Ua9evUL7o6Ki8PT0LHTfExIS2Lt3r+57MV111VVs3LiRdevWFWzt2rWjb9++Bf+se11yOnfu/I8h+omJidStWxeAevXqERwcXOh+Z2ZmsmLFCt3vYjp58iRuboW/vtzd3XE6nYDudWkpyn2NiYkhPT2d+Pj4gmN+++03nE4n0dHRF1fARXXZLeemTJlieHl5GZMnTza2bNliPPjgg0aVKlWM5ORkq0srsx555BEjICDAWLRokXHo0KGC7eTJkwXHPPzww0adOnWM3377zVi9erURExNjxMTEWFh1+fH3UUKGoXtdklauXGl4eHgYr732mrF9+3bj66+/Nnx9fY2vvvqq4JjXX3/dqFKlijFr1ixjw4YNRq9evTTU9gL079/fCA0NLRjWPGPGDKNGjRrG008/XXCM7vWFOX78uLF27Vpj7dq1BmC8/fbbxtq1a42kpCTDMIp2X3v06GG0adPGWLFihbFkyRKjUaNGGtZ8KYwfP96oU6eOYbfbjQ4dOhjLly+3uqQyDTjr9tlnnxUcc+rUKePRRx81qlatavj6+ho333yzcejQIeuKLkf+N7DoXpesH3/80YiIiDC8vLyMpk2bGh999FGh/U6n03j++eeNoKAgw8vLy7jqqquMhIQEi6otuzIzM42hQ4caderUMby9vY369esbzz33nJGTk1NwjO71hVm4cOFZf0f379/fMIyi3dcjR44Yffr0MSpXrmz4+/sbAwYMMI4fP37RtdkM429TA4qIiIi4IPVhEREREZenwCIiIiIuT4FFREREXJ4Ci4iIiLg8BRYRERFxeQosIiIi4vIUWERERMTlKbCIiIiIy1NgEREREZenwCIiIiIuT4FFREREXJ4Ci4iIiLi8/wdwhXFi2ONFHgAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'], label = 'train');\n","plt.plot(history.history['val_loss'], label = 'test');\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JutUMDJTFEm4"},"source":["<hr>\n","\n","# CALLBACKS"]},{"cell_type":"markdown","metadata":{"id":"XgKtGsXgKBsj"},"source":["### Early Stopping\n","\n","- `monitor = 'val_loss'` means that the validation loss is being monitored during the training.\n","\n","- `patience = 10` means that training will be stopped if the validation loss doesnt improve after 10 epochs.\n","\n","- `mode = 'min'` means whether the training should stop when the monitored quantity stops increasing or decreasing.\n","\n","- `verbose = 0`, it will be silent. If verbose=1, it will print a message when early stopping is triggered."]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":428,"status":"ok","timestamp":1708663260123,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"hUYjt5ArRx1a"},"outputs":[],"source":["from keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"]},{"cell_type":"markdown","metadata":{"id":"20NQXkHAKHK1"},"source":["### Model Checkpoints\n","\n","- The `mode` is set to 'max', which means that the models with the smallest accuracy will be saved.\n","\n","- The `save_best_only` parameter is set to True, which means that the latest best model according to the quantity monitored will not be overwritten.\n","\n","- If `verbose=1`, it will print out whether or not the model was saved after each epoch.\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1708663262769,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"6VqJH82QJAbT"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","\n","checkpoint = ModelCheckpoint(\"./model/best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"]},{"cell_type":"markdown","metadata":{"id":"SetxrWC-KKyw"},"source":["### Model Training with callbacks"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6704,"status":"ok","timestamp":1708663271206,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"XdZaJOlGIANZ","outputId":"dc99c53f-a18d-4e2a-8759-7f308a2f53bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.9000\n","Epoch 1: val_accuracy improved from -inf to 0.72857, saving model to ./model/best_model.h5\n","1/1 [==============================] - 0s 479ms/step - loss: 0.3668 - accuracy: 0.9000 - val_loss: 0.5106 - val_accuracy: 0.7286\n","Epoch 2/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.9000\n","Epoch 2: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3663 - accuracy: 0.9000 - val_loss: 0.5103 - val_accuracy: 0.7286\n","Epoch 3/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.9000\n","Epoch 3: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 45ms/step - loss: 0.3658 - accuracy: 0.9000 - val_loss: 0.5101 - val_accuracy: 0.7286\n","Epoch 4/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.9000\n","Epoch 4: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 46ms/step - loss: 0.3653 - accuracy: 0.9000 - val_loss: 0.5099 - val_accuracy: 0.7286\n","Epoch 5/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.9000"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 5: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3648 - accuracy: 0.9000 - val_loss: 0.5096 - val_accuracy: 0.7286\n","Epoch 6/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.9000\n","Epoch 6: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3643 - accuracy: 0.9000 - val_loss: 0.5094 - val_accuracy: 0.7286\n","Epoch 7/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.9000\n","Epoch 7: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3638 - accuracy: 0.9000 - val_loss: 0.5091 - val_accuracy: 0.7286\n","Epoch 8/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.9000\n","Epoch 8: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3633 - accuracy: 0.9000 - val_loss: 0.5089 - val_accuracy: 0.7286\n","Epoch 9/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.9000\n","Epoch 9: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 47ms/step - loss: 0.3628 - accuracy: 0.9000 - val_loss: 0.5086 - val_accuracy: 0.7286\n","Epoch 10/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.9000\n","Epoch 10: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 45ms/step - loss: 0.3623 - accuracy: 0.9000 - val_loss: 0.5084 - val_accuracy: 0.7286\n","Epoch 11/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.9000\n","Epoch 11: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3618 - accuracy: 0.9000 - val_loss: 0.5081 - val_accuracy: 0.7286\n","Epoch 12/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3613 - accuracy: 0.9000\n","Epoch 12: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 40ms/step - loss: 0.3613 - accuracy: 0.9000 - val_loss: 0.5079 - val_accuracy: 0.7286\n","Epoch 13/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.9000\n","Epoch 13: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3608 - accuracy: 0.9000 - val_loss: 0.5077 - val_accuracy: 0.7286\n","Epoch 14/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.9000\n","Epoch 14: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3604 - accuracy: 0.9000 - val_loss: 0.5074 - val_accuracy: 0.7286\n","Epoch 15/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.9000\n","Epoch 15: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 52ms/step - loss: 0.3599 - accuracy: 0.9000 - val_loss: 0.5072 - val_accuracy: 0.7286\n","Epoch 16/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.9000\n","Epoch 16: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3594 - accuracy: 0.9000 - val_loss: 0.5070 - val_accuracy: 0.7286\n","Epoch 17/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.9000\n","Epoch 17: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 53ms/step - loss: 0.3589 - accuracy: 0.9000 - val_loss: 0.5067 - val_accuracy: 0.7286\n","Epoch 18/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.9000\n","Epoch 18: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3584 - accuracy: 0.9000 - val_loss: 0.5065 - val_accuracy: 0.7286\n","Epoch 19/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.9000\n","Epoch 19: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3580 - accuracy: 0.9000 - val_loss: 0.5063 - val_accuracy: 0.7286\n","Epoch 20/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.9000\n","Epoch 20: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3575 - accuracy: 0.9000 - val_loss: 0.5060 - val_accuracy: 0.7286\n","Epoch 21/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9000\n","Epoch 21: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3570 - accuracy: 0.9000 - val_loss: 0.5058 - val_accuracy: 0.7286\n","Epoch 22/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.9000\n","Epoch 22: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3565 - accuracy: 0.9000 - val_loss: 0.5056 - val_accuracy: 0.7286\n","Epoch 23/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 0.9000\n","Epoch 23: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3561 - accuracy: 0.9000 - val_loss: 0.5053 - val_accuracy: 0.7286\n","Epoch 24/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.9000\n","Epoch 24: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3556 - accuracy: 0.9000 - val_loss: 0.5051 - val_accuracy: 0.7286\n","Epoch 25/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.9000\n","Epoch 25: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3551 - accuracy: 0.9000 - val_loss: 0.5049 - val_accuracy: 0.7286\n","Epoch 26/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.9000\n","Epoch 26: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3547 - accuracy: 0.9000 - val_loss: 0.5046 - val_accuracy: 0.7286\n","Epoch 27/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.9000\n","Epoch 27: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 40ms/step - loss: 0.3542 - accuracy: 0.9000 - val_loss: 0.5044 - val_accuracy: 0.7286\n","Epoch 28/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.9000\n","Epoch 28: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3537 - accuracy: 0.9000 - val_loss: 0.5042 - val_accuracy: 0.7286\n","Epoch 29/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.9000\n","Epoch 29: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3533 - accuracy: 0.9000 - val_loss: 0.5040 - val_accuracy: 0.7286\n","Epoch 30/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.9000\n","Epoch 30: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3528 - accuracy: 0.9000 - val_loss: 0.5037 - val_accuracy: 0.7286\n","Epoch 31/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.9000\n","Epoch 31: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3524 - accuracy: 0.9000 - val_loss: 0.5035 - val_accuracy: 0.7286\n","Epoch 32/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.9000\n","Epoch 32: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3519 - accuracy: 0.9000 - val_loss: 0.5033 - val_accuracy: 0.7286\n","Epoch 33/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.9000\n","Epoch 33: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 47ms/step - loss: 0.3515 - accuracy: 0.9000 - val_loss: 0.5031 - val_accuracy: 0.7286\n","Epoch 34/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.9000\n","Epoch 34: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 53ms/step - loss: 0.3510 - accuracy: 0.9000 - val_loss: 0.5029 - val_accuracy: 0.7286\n","Epoch 35/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.9000\n","Epoch 35: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3506 - accuracy: 0.9000 - val_loss: 0.5026 - val_accuracy: 0.7286\n","Epoch 36/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.9000\n","Epoch 36: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3501 - accuracy: 0.9000 - val_loss: 0.5024 - val_accuracy: 0.7286\n","Epoch 37/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.9000\n","Epoch 37: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3497 - accuracy: 0.9000 - val_loss: 0.5022 - val_accuracy: 0.7286\n","Epoch 38/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.9000\n","Epoch 38: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3492 - accuracy: 0.9000 - val_loss: 0.5020 - val_accuracy: 0.7286\n","Epoch 39/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.9000\n","Epoch 39: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3488 - accuracy: 0.9000 - val_loss: 0.5018 - val_accuracy: 0.7286\n","Epoch 40/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9000\n","Epoch 40: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3484 - accuracy: 0.9000 - val_loss: 0.5016 - val_accuracy: 0.7286\n","Epoch 41/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.9000\n","Epoch 41: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 61ms/step - loss: 0.3479 - accuracy: 0.9000 - val_loss: 0.5014 - val_accuracy: 0.7286\n","Epoch 42/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.9000\n","Epoch 42: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3475 - accuracy: 0.9000 - val_loss: 0.5011 - val_accuracy: 0.7286\n","Epoch 43/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.9000\n","Epoch 43: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3470 - accuracy: 0.9000 - val_loss: 0.5009 - val_accuracy: 0.7286\n","Epoch 44/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.9000\n","Epoch 44: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3466 - accuracy: 0.9000 - val_loss: 0.5007 - val_accuracy: 0.7286\n","Epoch 45/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.9000\n","Epoch 45: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 47ms/step - loss: 0.3462 - accuracy: 0.9000 - val_loss: 0.5005 - val_accuracy: 0.7286\n","Epoch 46/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.9000\n","Epoch 46: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3457 - accuracy: 0.9000 - val_loss: 0.5003 - val_accuracy: 0.7286\n","Epoch 47/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.9000\n","Epoch 47: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3453 - accuracy: 0.9000 - val_loss: 0.5001 - val_accuracy: 0.7286\n","Epoch 48/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.9000\n","Epoch 48: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3449 - accuracy: 0.9000 - val_loss: 0.4999 - val_accuracy: 0.7286\n","Epoch 49/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.9000\n","Epoch 49: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3445 - accuracy: 0.9000 - val_loss: 0.4997 - val_accuracy: 0.7286\n","Epoch 50/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.9000\n","Epoch 50: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3440 - accuracy: 0.9000 - val_loss: 0.4995 - val_accuracy: 0.7286\n","Epoch 51/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.9000\n","Epoch 51: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3436 - accuracy: 0.9000 - val_loss: 0.4993 - val_accuracy: 0.7286\n","Epoch 52/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.9000\n","Epoch 52: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 58ms/step - loss: 0.3432 - accuracy: 0.9000 - val_loss: 0.4991 - val_accuracy: 0.7286\n","Epoch 53/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.9000\n","Epoch 53: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 49ms/step - loss: 0.3428 - accuracy: 0.9000 - val_loss: 0.4989 - val_accuracy: 0.7286\n","Epoch 54/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.9000\n","Epoch 54: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3424 - accuracy: 0.9000 - val_loss: 0.4987 - val_accuracy: 0.7286\n","Epoch 55/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.9000\n","Epoch 55: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 58ms/step - loss: 0.3419 - accuracy: 0.9000 - val_loss: 0.4985 - val_accuracy: 0.7286\n","Epoch 56/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.9000\n","Epoch 56: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 45ms/step - loss: 0.3415 - accuracy: 0.9000 - val_loss: 0.4983 - val_accuracy: 0.7286\n","Epoch 57/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.9000\n","Epoch 57: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3411 - accuracy: 0.9000 - val_loss: 0.4981 - val_accuracy: 0.7286\n","Epoch 58/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.9000\n","Epoch 58: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3407 - accuracy: 0.9000 - val_loss: 0.4979 - val_accuracy: 0.7286\n","Epoch 59/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.9000\n","Epoch 59: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3403 - accuracy: 0.9000 - val_loss: 0.4977 - val_accuracy: 0.7286\n","Epoch 60/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.9000\n","Epoch 60: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 63ms/step - loss: 0.3399 - accuracy: 0.9000 - val_loss: 0.4975 - val_accuracy: 0.7286\n","Epoch 61/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.9000\n","Epoch 61: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3395 - accuracy: 0.9000 - val_loss: 0.4973 - val_accuracy: 0.7286\n","Epoch 62/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.9000\n","Epoch 62: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 48ms/step - loss: 0.3391 - accuracy: 0.9000 - val_loss: 0.4971 - val_accuracy: 0.7286\n","Epoch 63/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.9000\n","Epoch 63: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3387 - accuracy: 0.9000 - val_loss: 0.4969 - val_accuracy: 0.7286\n","Epoch 64/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.9000\n","Epoch 64: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3382 - accuracy: 0.9000 - val_loss: 0.4967 - val_accuracy: 0.7286\n","Epoch 65/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9000\n","Epoch 65: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3378 - accuracy: 0.9000 - val_loss: 0.4965 - val_accuracy: 0.7286\n","Epoch 66/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.9000\n","Epoch 66: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3374 - accuracy: 0.9000 - val_loss: 0.4963 - val_accuracy: 0.7286\n","Epoch 67/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.9000\n","Epoch 67: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 56ms/step - loss: 0.3370 - accuracy: 0.9000 - val_loss: 0.4961 - val_accuracy: 0.7286\n","Epoch 68/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.9000\n","Epoch 68: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3366 - accuracy: 0.9000 - val_loss: 0.4960 - val_accuracy: 0.7286\n","Epoch 69/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.9000\n","Epoch 69: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3362 - accuracy: 0.9000 - val_loss: 0.4958 - val_accuracy: 0.7286\n","Epoch 70/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9000\n","Epoch 70: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3359 - accuracy: 0.9000 - val_loss: 0.4956 - val_accuracy: 0.7286\n","Epoch 71/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.9000\n","Epoch 71: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3355 - accuracy: 0.9000 - val_loss: 0.4954 - val_accuracy: 0.7286\n","Epoch 72/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.9000\n","Epoch 72: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3351 - accuracy: 0.9000 - val_loss: 0.4952 - val_accuracy: 0.7286\n","Epoch 73/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.9000\n","Epoch 73: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3347 - accuracy: 0.9000 - val_loss: 0.4950 - val_accuracy: 0.7286\n","Epoch 74/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.9000\n","Epoch 74: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 47ms/step - loss: 0.3343 - accuracy: 0.9000 - val_loss: 0.4948 - val_accuracy: 0.7286\n","Epoch 75/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.9000\n","Epoch 75: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 43ms/step - loss: 0.3339 - accuracy: 0.9000 - val_loss: 0.4947 - val_accuracy: 0.7286\n","Epoch 76/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.9000\n","Epoch 76: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 55ms/step - loss: 0.3335 - accuracy: 0.9000 - val_loss: 0.4945 - val_accuracy: 0.7286\n","Epoch 77/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.9000\n","Epoch 77: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9000 - val_loss: 0.4943 - val_accuracy: 0.7286\n","Epoch 78/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.9000\n","Epoch 78: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 46ms/step - loss: 0.3327 - accuracy: 0.9000 - val_loss: 0.4941 - val_accuracy: 0.7286\n","Epoch 79/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.9000\n","Epoch 79: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3324 - accuracy: 0.9000 - val_loss: 0.4939 - val_accuracy: 0.7286\n","Epoch 80/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.9000\n","Epoch 80: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 37ms/step - loss: 0.3320 - accuracy: 0.9000 - val_loss: 0.4938 - val_accuracy: 0.7286\n","Epoch 81/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.9000\n","Epoch 81: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 51ms/step - loss: 0.3316 - accuracy: 0.9000 - val_loss: 0.4936 - val_accuracy: 0.7286\n","Epoch 82/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.9000\n","Epoch 82: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3312 - accuracy: 0.9000 - val_loss: 0.4934 - val_accuracy: 0.7286\n","Epoch 83/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8667\n","Epoch 83: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3308 - accuracy: 0.8667 - val_loss: 0.4932 - val_accuracy: 0.7286\n","Epoch 84/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8667\n","Epoch 84: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 53ms/step - loss: 0.3305 - accuracy: 0.8667 - val_loss: 0.4930 - val_accuracy: 0.7286\n","Epoch 85/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8667\n","Epoch 85: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 42ms/step - loss: 0.3301 - accuracy: 0.8667 - val_loss: 0.4929 - val_accuracy: 0.7286\n","Epoch 86/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8667\n","Epoch 86: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 41ms/step - loss: 0.3297 - accuracy: 0.8667 - val_loss: 0.4927 - val_accuracy: 0.7286\n","Epoch 87/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8667\n","Epoch 87: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3293 - accuracy: 0.8667 - val_loss: 0.4925 - val_accuracy: 0.7286\n","Epoch 88/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.8667\n","Epoch 88: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 48ms/step - loss: 0.3290 - accuracy: 0.8667 - val_loss: 0.4923 - val_accuracy: 0.7286\n","Epoch 89/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8667\n","Epoch 89: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 44ms/step - loss: 0.3286 - accuracy: 0.8667 - val_loss: 0.4922 - val_accuracy: 0.7286\n","Epoch 90/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8667\n","Epoch 90: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 59ms/step - loss: 0.3282 - accuracy: 0.8667 - val_loss: 0.4920 - val_accuracy: 0.7286\n","Epoch 91/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8667\n","Epoch 91: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 57ms/step - loss: 0.3279 - accuracy: 0.8667 - val_loss: 0.4918 - val_accuracy: 0.7286\n","Epoch 92/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8667\n","Epoch 92: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 46ms/step - loss: 0.3275 - accuracy: 0.8667 - val_loss: 0.4917 - val_accuracy: 0.7286\n","Epoch 93/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8667\n","Epoch 93: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 71ms/step - loss: 0.3271 - accuracy: 0.8667 - val_loss: 0.4915 - val_accuracy: 0.7286\n","Epoch 94/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.8667\n","Epoch 94: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 60ms/step - loss: 0.3268 - accuracy: 0.8667 - val_loss: 0.4913 - val_accuracy: 0.7286\n","Epoch 95/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.8667\n","Epoch 95: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 68ms/step - loss: 0.3264 - accuracy: 0.8667 - val_loss: 0.4911 - val_accuracy: 0.7286\n","Epoch 96/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.8667\n","Epoch 96: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 77ms/step - loss: 0.3261 - accuracy: 0.8667 - val_loss: 0.4910 - val_accuracy: 0.7286\n","Epoch 97/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8667\n","Epoch 97: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 73ms/step - loss: 0.3257 - accuracy: 0.8667 - val_loss: 0.4908 - val_accuracy: 0.7286\n","Epoch 98/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8667\n","Epoch 98: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 64ms/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 0.4906 - val_accuracy: 0.7286\n","Epoch 99/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8667\n","Epoch 99: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 73ms/step - loss: 0.3250 - accuracy: 0.8667 - val_loss: 0.4905 - val_accuracy: 0.7286\n","Epoch 100/100\n","1/1 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8667\n","Epoch 100: val_accuracy did not improve from 0.72857\n","1/1 [==============================] - 0s 73ms/step - loss: 0.3246 - accuracy: 0.8667 - val_loss: 0.4903 - val_accuracy: 0.7286\n"]}],"source":["history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), callbacks=[early_stopping, checkpoint])"]},{"cell_type":"markdown","metadata":{"id":"brJ4hAiPRG1f"},"source":["### Saving Model History Explicitly"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1708663302806,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"P5UjzD-WRJac"},"outputs":[],"source":["import pickle\n","\n","with open('./model/best_model_history.pkl', 'wb') as f:\n","    pickle.dump(history.history, f)"]},{"cell_type":"markdown","metadata":{"id":"PIoT5XiYLZVP"},"source":["# LOADING SAVED MODELS"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1708663328845,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"asTk-eQeIJ5q"},"outputs":[],"source":["from keras.models import load_model\n","\n","loaded_model = load_model('./model/best_model.h5')"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1708663330605,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"4UtREtDGLt11","outputId":"bb10cd14-6e2e-4394-9568-31c5dcc8af1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 500)               1500      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 501       \n","                                                                 \n","=================================================================\n","Total params: 2001 (7.82 KB)\n","Trainable params: 2001 (7.82 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["loaded_model.summary()"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":686,"status":"ok","timestamp":1708663333412,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"Fl9vN20ALwBr","outputId":"1ec58d25-703c-493d-a4b0-a51a1ae33b14"},"outputs":[{"name":"stdout","output_type":"stream","text":["ACTUAL VALUE :  1\n","1/1 [==============================] - 0s 76ms/step\n","1/1 [==============================] - 0s 31ms/step\n","PREDICTED VALUE : 0.8270606398582458 >>>>> Approximately : 1\n"]}],"source":["print(\"ACTUAL VALUE : \",y_train[0])\n","\n","print(f\"PREDICTED VALUE : {loaded_model.predict([[ 1.36698238, -0.23541584]])[0][0]} >>>>> Approximately : {round(loaded_model.predict([[ 1.36698238, -0.23541584]])[0][0])}\")"]},{"cell_type":"markdown","metadata":{"id":"S-5fFQ9tPfRw"},"source":["### Evaluating the Loaded Model"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1708663523600,"user":{"displayName":"AYUSHMAAN DAS BTech_AIML","userId":"16690242712608209106"},"user_tz":-330},"id":"UP_sAGenM0LM","outputId":"644ac06a-5137-4e4d-ef05-783b84149381"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 380ms/step - loss: 0.3663 - accuracy: 0.9000\n","1/1 [==============================] - 0s 102ms/step - loss: 0.5106 - accuracy: 0.7286\n","TRAIN ACCURACY 0.8999999761581421\n","TEST ACCURACY 0.7285714149475098\n"]}],"source":["_, train_acc = loaded_model.evaluate(x_train, y_train, verbose = 1)\n","\n","test_loss, test_acc = loaded_model.evaluate(x_test, y_test, verbose = 1, batch_size = len(x_test))\n","\n","print(\"TRAIN ACCURACY\", train_acc)\n","print(\"TEST ACCURACY\", test_acc)"]},{"cell_type":"markdown","metadata":{"id":"f0rEAEUtRYYz"},"source":["### Reading Model History"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jt16t5tYQgDx"},"outputs":[],"source":["with open('./model/best_model_history.pkl', 'rb') as f:\n","    loaded_history = pickle.load(f)\n","\n","plt.plot(loaded_history['loss'], label = 'train');\n","plt.plot(loaded_history['val_loss'], label = 'test');\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Cl82d28KpJHX"},"source":["<hr><hr>"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOmOZnH3XLwzvxebcfwDgxW","gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
